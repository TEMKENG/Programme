\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\BKM@entry[2]{}
\AC@reset@newl@bel
\providecommand \oddpage@label [2]{}
\babel@aux{ngerman}{}
\babel@aux{ngerman}{}
\AC@undonewlabel{acro:DNN}
\newlabel{acro:DNN}{{}{3}{\list@fname }{section*.3}{}}
\acronymused{DNN}
\acronymused{CNN}
\newacro{KNN}[\AC@hyperlink{KNN}{KNN}]{K\IeC {\"u}nstliches neuronales Netz}
\newacro{CNN}[\AC@hyperlink{CNN}{CNN}]{Convolutional Neural Network}
\newacro{KI}[\AC@hyperlink{KI}{KI}]{K\IeC {\"u}nstliche Intelligenz}
\newacro{NN}[\AC@hyperlink{NN}{NN}]{neuronales Netz}
\newacro{ConvL}[\AC@hyperlink{ConvL}{ConvL}]{Convolutional Layer}
\newacro{FCL}[\AC@hyperlink{FCL}{FCL}]{Fully Connected Layer}
\newacro{PooL}[\AC@hyperlink{PooL}{PooL}]{Pooling Layer}
\newacro{ILSVRC }[\AC@hyperlink{ILSVRC }{ILSVRC }]{ Large Scale Visual Recognition Challenge}
\newacro{DNN}[\AC@hyperlink{DNN}{DNN}]{Tiefe neuronale Netze}
\newacro{ML}[\AC@hyperlink{ML}{ML}]{Maschine Lernen}
\newacro{DSC}[\AC@hyperlink{DSC}{DSC}]{Depthwise Separable Convolution}
\BKM@entry{id=1,dest={73656374696F6E2E31},srcline={132}}{45696E6C656974756E67}
\@writefile{toc}{\contentsline {section}{\numberline {1}Einleitung}{5}{section.1}}
\BKM@entry{id=2,dest={73656374696F6E2E32},srcline={140}}{4772756E646C6167656E}
\BKM@entry{id=3,dest={73756273656374696F6E2E322E31},srcline={141}}{4E6575726F6E}
\citation{kneuron}
\BKM@entry{id=4,dest={73756273656374696F6E2E322E32},srcline={215}}{4D65726B6D616C736B617274656E5C28466561747572652D4D6170735C29}
\BKM@entry{id=5,dest={73756273656374696F6E2E322E33},srcline={220}}{46696C74657273}
\@writefile{toc}{\contentsline {section}{\numberline {2}Grundlagen}{6}{section.2}}
\newlabel{Grundlaagen}{{2}{6}{Grundlagen}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Neuron}{6}{subsection.2.1}}
\AC@undonewlabel{acro:KNN}
\newlabel{acro:KNN}{{2.1}{6}{Neuron}{section*.4}{}}
\acronymused{KNN}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Funktionsweise eines k\IeC {\"u}nstlichen Neurons \relax }}{6}{figure.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Fneuron}{{1}{6}{Funktionsweise eines künstlichen Neurons \relax }{figure.caption.5}{}}
\acronymused{KNN}
\AC@undonewlabel{acro:NN}
\newlabel{acro:NN}{{2.1}{6}{Neuron}{section*.6}{}}
\acronymused{NN}
\acronymused{KNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Merkmalskarten(Feature-Maps)}{6}{subsection.2.2}}
\AC@undonewlabel{acro:FCL}
\newlabel{acro:FCL}{{2.2}{6}{Merkmalskarten(Feature-Maps)}{section*.7}{}}
\acronymused{FCL}
\BKM@entry{id=6,dest={73756273656374696F6E2E322E34},srcline={266}}{456E747769636B6C756E6720766F6E204B5C3337346E73746C696368656E204E6575726F6E616C656E204E65747A656E}
\BKM@entry{id=7,dest={73656374696F6E2E33},srcline={273}}{436F6E766F6C7574696F6E616C204E657572616C204E6574776F726B}
\BKM@entry{id=8,dest={73756273656374696F6E2E332E31},srcline={274}}{46656564666F7277617264}
\BKM@entry{id=9,dest={73756273756273656374696F6E2E332E312E31},srcline={276}}{496E707574204C61796572}
\BKM@entry{id=10,dest={73756273756273656374696F6E2E332E312E32},srcline={280}}{46616C74756E677373636869636874}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Filters}{7}{subsection.2.3}}
\newlabel{Filter}{{2.3}{7}{Filters}{subsection.2.3}{}}
\AC@undonewlabel{acro:CNN}
\newlabel{acro:CNN}{{2.3}{7}{Filters}{section*.8}{}}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Entwicklung von K\IeC {\"u}nstlichen Neuronalen Netzen}{7}{subsection.2.4}}
\newlabel{Entwicklung}{{2.4}{7}{Entwicklung von Künstlichen Neuronalen Netzen}{subsection.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Convolutional Neural Network}{7}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Feedforward}{7}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Input Layer}{7}{subsubsection.3.1.1}}
\newlabel{InputLayer}{{3.1.1}{7}{Input Layer}{subsubsection.3.1.1}{}}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Faltungsschicht}{7}{subsubsection.3.1.2}}
\newlabel{ConvL}{{3.1.2}{7}{Faltungsschicht}{subsubsection.3.1.2}{}}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\AC@undonewlabel{acro:ConvL}
\newlabel{acro:ConvL}{{3.1.2}{8}{Faltungsschicht}{section*.9}{}}
\acronymused{ConvL}
\acronymused{ConvL}
\acronymused{ConvL}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Einfluss der Schrittgr\IeC {\"o}\IeC {\ss }e auf die Gr\IeC {\"o}\IeC {\ss }e der Feature-Maps\relax }}{8}{figure.caption.10}}
\newlabel{fig:stride1}{{3a}{8}{\emph {Schrittgröße=(1,1) } \relax }{figure.caption.10}{}}
\newlabel{sub@fig:stride1}{{a}{8}{\emph {Schrittgröße=(1,1) } \relax }{figure.caption.10}{}}
\newlabel{fig:stride2}{{3b}{8}{\emph {Schrittgröße=(2,2) } \relax }{figure.caption.10}{}}
\newlabel{sub@fig:stride2}{{b}{8}{\emph {Schrittgröße=(2,2) } \relax }{figure.caption.10}{}}
\BKM@entry{id=11,dest={73756273756273656374696F6E2E332E312E33},srcline={405}}{416B746976696572756E677366756E6B74696F6E}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Auswirkung von Schrittgr\IeC {\"o}\IeC {\ss }e,Filtergr\IeC {\"o}\IeC {\ss }e und Padding auf Output eines $ (100, 100, 3) $ Bild.\relax }}{9}{table.caption.11}}
\newlabel{tab:Stride and filter size}{{1}{9}{Auswirkung von Schrittgröße,Filtergröße und Padding auf Output eines $ (100, 100, 3) $ Bild.\relax }{table.caption.11}{}}
\acronymused{ConvL}
\acronymused{CNN}
\acronymused{ConvL}
\acronymused{ConvL}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Aktivierungsfunktion}{9}{subsubsection.3.1.3}}
\acronymused{NN}
\pgfsyspdfmark {pgfid2}{6784065}{47574687}
\pgfsyspdfmark {pgfid3}{13026345}{47574687}
\pgfsyspdfmark {pgfid4}{7824445}{46624416}
\pgfsyspdfmark {pgfid5}{8864825}{45674145}
\pgfsyspdfmark {pgfid6}{15107105}{45674145}
\pgfsyspdfmark {pgfid7}{6784065}{44723874}
\pgfsyspdfmark {pgfid8}{9905205}{44723874}
\pgfsyspdfmark {pgfid9}{8864825}{42823332}
\pgfsyspdfmark {pgfid10}{11985965}{42823332}
\pgfsyspdfmark {pgfid11}{6784065}{41873061}
\pgfsyspdfmark {pgfid12}{13026345}{41873061}
\pgfsyspdfmark {pgfid13}{14066725}{40922790}
\pgfsyspdfmark {pgfid14}{8864825}{39972519}
\pgfsyspdfmark {pgfid15}{15107105}{39972519}
\pgfsyspdfmark {pgfid16}{28911618}{44750088}
\pgfsyspdfmark {pgfid17}{31044576}{44750088}
\pgfsyspdfmark {pgfid18}{28911618}{43773603}
\pgfsyspdfmark {pgfid19}{29977982}{43773603}
\pgfsyspdfmark {pgfid20}{28911618}{42797118}
\pgfsyspdfmark {pgfid21}{31044576}{42797118}
\pgfsyspdfmark {pgfid22}{19450952}{37563616}
\newlabel{fig:Faltungsoperation1}{{4a}{10}{Matrixdarstellung\relax }{figure.caption.12}{}}
\newlabel{sub@fig:Faltungsoperation1}{{a}{10}{Matrixdarstellung\relax }{figure.caption.12}{}}
\newlabel{fig:Faltungsoperation2}{{4b}{10}{Pixeldarstellung \relax }{figure.caption.12}{}}
\newlabel{sub@fig:Faltungsoperation2}{{b}{10}{Pixeldarstellung \relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Faltungsoperation mit einem $ 3\times 3$-Filter und Schrittgr\IeC {\"o}\IeC {\ss }e $ =3 $\relax }}{10}{figure.caption.12}}
\newlabel{fig:Faltungsoperation}{{4}{10}{Faltungsoperation mit einem $ 3\times 3$-Filter und Schrittgröße $ =3 $\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Bin\IeC {\"a}re Treppenfunktion\relax }}{11}{figure.caption.13}}
\newlabel{fig:Treppenfunktion}{{5}{11}{Binäre Treppenfunktion\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Lineare Funktion\relax }}{11}{figure.caption.14}}
\newlabel{fig:Lineare Funktion}{{7}{11}{Lineare Funktion\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Logistische Aktivierungsfunktion:$ sigmoid(x) $.\relax }}{12}{figure.caption.15}}
\newlabel{fig:sigmoid}{{9}{12}{Logistische Aktivierungsfunktion:$ sigmoid(x) $.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Tangens Hyperbolicus.\relax }}{12}{figure.caption.16}}
\newlabel{fig:tanh}{{11}{12}{Tangens Hyperbolicus.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces ReLU Aktivierungsfunktion\relax }}{12}{figure.caption.17}}
\newlabel{fig:relu}{{13}{12}{ReLU Aktivierungsfunktion\relax }{figure.caption.17}{}}
\BKM@entry{id=12,dest={73756273756273656374696F6E2E332E312E34},srcline={587}}{506F6F6C696E67204C61796572}
\citation{4}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Leaky ReLU Funktion\relax }}{13}{figure.caption.18}}
\newlabel{fig:LReLU}{{15}{13}{Leaky ReLU Funktion\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}Pooling Layer}{13}{subsubsection.3.1.4}}
\newlabel{Pooling Layer}{{3.1.4}{13}{Pooling Layer}{subsubsection.3.1.4}{}}
\acronymused{ConvL}
\acronymused{ConvL}
\AC@undonewlabel{acro:PooL}
\newlabel{acro:PooL}{{3.1.4}{13}{Pooling Layer}{section*.20}{}}
\acronymused{PooL}
\acronymused{PooL}
\BKM@entry{id=13,dest={73756273756273656374696F6E2E332E312E35},srcline={718}}{4D756C74692D6C61796572205065727A657074726F6E205C2846756C6C7920436F6E6E6563746564204C617965725C29}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Funktionsweise der Pooling-Sicht mit Pooling\_size$ =(2,2) $ und $ Stride =2$\relax }}{14}{figure.caption.19}}
\newlabel{fig:Pooling}{{17}{14}{Funktionsweise der Pooling-Sicht mit Pooling\_size$ =(2,2) $ und $ Stride =2$\relax }{figure.caption.19}{}}
\acronymused{ConvL}
\acronymused{FCL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.5}Multi-layer Perzeptron (Fully Connected Layer)}{14}{subsubsection.3.1.5}}
\newlabel{FC}{{3.1.5}{14}{Multi-layer Perzeptron (Fully Connected Layer)}{subsubsection.3.1.5}{}}
\acronymused{FCL}
\acronymused{FCL}
\acronymused{CNN}
\acronymused{FCL}
\acronymused{ConvL}
\acronymused{FCL}
\acronymused{NN}
\acronymused{FCL}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Darstellung eines neuronalen Netzes \relax }}{14}{figure.caption.21}}
\newlabel{KNN}{{18}{14}{Darstellung eines neuronalen Netzes \relax }{figure.caption.21}{}}
\acronymused{FCL}
\BKM@entry{id=14,dest={73756273656374696F6E2E332E32},srcline={779}}{4261636B666F7277617264}
\BKM@entry{id=15,dest={73756273756273656374696F6E2E332E322E31},srcline={781}}{4665686C657266756E6B74696F6E}
\citation{7}
\BKM@entry{id=16,dest={73756273756273656374696F6E2E332E322E32},srcline={803}}{4772616469656E74}
\acronymused{FCL}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Backforward}{15}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Fehlerfunktion}{15}{subsubsection.3.2.1}}
\newlabel{Fehlerfunktion}{{3.2.1}{15}{Fehlerfunktion}{subsubsection.3.2.1}{}}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{NN}
\acronymused{CNN}
\acronymused{CNN}
\newlabel{MSE}{{3.1}{15}{Fehlerfunktion}{equation.3.1}{}}
\newlabel{CE}{{3.2}{15}{Fehlerfunktion}{equation.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Gradient}{15}{subsubsection.3.2.2}}
\newlabel{Gradient}{{3.2.2}{15}{Gradient}{subsubsection.3.2.2}{}}
\BKM@entry{id=17,dest={73756273756273656374696F6E2E332E322E33},srcline={807}}{4C65726E72617465}
\citation{LearningRate}
\BKM@entry{id=18,dest={73756273756273656374696F6E2E332E322E34},srcline={813}}{4772616469656E74656E616273746965677376657266616872656E}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Lernrate}{16}{subsubsection.3.2.3}}
\newlabel{Lernrate}{{3.2.3}{16}{Lernrate}{subsubsection.3.2.3}{}}
\acronymused{NN}
\acronymused{NN}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Gradientenabstiegsverfahren}{16}{subsubsection.3.2.4}}
\newlabel{Gradientenabstiegsverfahren}{{3.2.4}{16}{Gradientenabstiegsverfahren}{subsubsection.3.2.4}{}}
\acronymused{DNN}
\acronymused{DNN}
\acronymused{DNN}
\acronymused{NN}
\citation{CNNStory}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Ablauf der Backpropagation\relax }}{17}{figure.caption.22}}
\newlabel{fig:Backprop}{{19}{17}{Ablauf der Backpropagation\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Stochastic Gradient Descent (SGD)}{17}{section*.23}}
\acronymused{NN}
\citation{CNNStory}
\acronymused{NN}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Stochastic Gradient descent(SGD) \cite  {CNNStory}.\relax }}{18}{algocf.1}}
\newlabel{alg:SGD}{{1}{18}{Stochastic Gradient Descent (SGD)}{algocf.1}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Batch Gradient Descent (BGD)}{18}{section*.25}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Batch Gradient descent \cite  {CNNStory}.\relax }}{18}{algocf.2}}
\newlabel{alg:BGD}{{2}{18}{Batch Gradient Descent (BGD)}{algocf.2}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Mini-batch Stochastic Gradient Descent(MSGD):}{18}{section*.27}}
\citation{CNNStory}
\BKM@entry{id=19,dest={73656374696F6E2E34},srcline={929}}{4B6F6D7072657373696F6E20766F6E20444E4E}
\BKM@entry{id=20,dest={73756273656374696F6E2E342E31},srcline={939}}{5072756E696E67204E6574776F726B}
\acronymused{DNN}
\acronymused{NN}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Mini-Batch Stochastic Gradient descent(MSGD) \cite  {CNNStory}.\relax }}{19}{algocf.3}}
\newlabel{alg:MSGD}{{3}{19}{Mini-batch Stochastic Gradient Descent(MSGD):}{algocf.3}{}}
\acronymused{DNN}
\@writefile{toc}{\contentsline {section}{\numberline {4}Kompression von \ac {DNN}}{19}{section.4}}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{DNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Pruning Network}{20}{subsection.4.1}}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\citation{pruning}
\citation{Filter Pruning}
\citation{Filter Pruning}
\acronymused{DNN}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces  Netzbeschneidung w\IeC {\"a}hrend des Trainings\relax }}{21}{figure.caption.29}}
\newlabel{fig:PN}{{20}{21}{Netzbeschneidung während des Trainings\relax }{figure.caption.29}{}}
\newlabel{Schwellenwert}{{4.1}{21}{Pruning Network}{figure.caption.29}{}}
\acronymused{NN}
\acronymused{NN}
\acronymused{FCL}
\acronymused{ConvL}
\acronymused{CNN}
\acronymused{NN}
\citation{Filter Pruning}
\citation{Filter Pruning}
\citation{Filter Pruning}
\acronymused{DNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{NN}
\newlabel{eq:l_1}{{4.1}{22}{Pruning Network}{equation.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Einfluss der Intensit\IeC {\"a}t des Filters auf Feature-Map\relax }}{22}{figure.caption.30}}
\newlabel{fig:Filter_Intensit\IeC {\"a}t}{{21}{22}{Einfluss der Intensität des Filters auf Feature-Map\relax }{figure.caption.30}{}}
\citation{Automated Pruning}
\citation{pruning}
\BKM@entry{id=21,dest={73756273656374696F6E2E342E32},srcline={1021}}{5175616E746973696572756E6720766F6E206E6575726F6E616C656E204E65747A7765726B656E}
\acronymused{DNN}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces  Das Beschneiden eines Filters f\IeC {\"u}hrt zum Entfernen der entsprechenden Feature-Map und der zugeh\IeC {\"o}rigen Kernel in der n\IeC {\"a}chsten Ebene\cite  {Filter Pruning}.\relax }}{23}{figure.caption.31}}
\newlabel{fig:Filter_pruning}{{22}{23}{Das Beschneiden eines Filters führt zum Entfernen der entsprechenden Feature-Map und der zugehörigen Kernel in der nächsten Ebene\cite {Filter Pruning}.\relax }{figure.caption.31}{}}
\citation{matrix quantization}
\acronymused{DNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Quantisierung von neuronalen Netzwerken}{24}{subsection.4.2}}
\AC@undonewlabel{acro:ML}
\newlabel{acro:ML}{{4.2}{24}{Quantisierung von neuronalen Netzwerken}{section*.32}{}}
\acronymused{ML}
\newlabel{eq:SVD}{{4.2}{24}{Quantisierung von neuronalen Netzwerken}{equation.4.2}{}}
\acronymused{NN}
\citation{quantization1}
\acronymused{DNN}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Parameter Approximieren durch Matrixfaktorisierung \relax }}{25}{figure.caption.33}}
\newlabel{fig:matrix_fatorization}{{23}{25}{Parameter Approximieren durch Matrixfaktorisierung \relax }{figure.caption.33}{}}
\acronymused{ML}
\acronymused{NN}
\citation{quantizationYoni}
\citation{quantizationYoni}
\citation{quantizationYoni}
\citation{quantizationYoni}
\BKM@entry{id=22,dest={73756273656374696F6E2E342E33},srcline={1075}}{487566666D616E20436F64696572756E67}
\BKM@entry{id=23,dest={73656374696F6E2E35},srcline={1078}}{4578706572696D656E74}
\BKM@entry{id=24,dest={73756273656374696F6E2E352E31},srcline={1081}}{45696E666C75737320646572204C65726E72617465}
\acronymused{NN}
\acronymused{NN}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Huffman Codierung}{26}{subsection.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiment}{26}{section.5}}
\newlabel{Experiment}{{5}{26}{Experiment}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Einfluss der Lernrate}{26}{subsection.5.1}}
\newlabel{Experiment:Lernrate}{{5.1}{26}{Einfluss der Lernrate}{subsection.5.1}{}}
\BKM@entry{id=25,dest={73756273656374696F6E2E352E32},srcline={1090}}{436F6E766F6C7574696F6E204C6179657273}
\acronymused{CNN}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Convolution Layers}{27}{subsection.5.2}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Standard Convolution}{27}{section*.34}}
\newlabel{eq:outputSize}{{5.1}{27}{Standard Convolution}{equation.5.1}{}}
\newlabel{eq:SF_kost}{{5.2}{28}{Standard Convolution}{equation.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Anwendung einer Standardfaltung auf ein Farbbild.\relax }}{28}{figure.caption.35}}
\newlabel{fig:Standardfaltung}{{24}{28}{Anwendung einer Standardfaltung auf ein Farbbild.\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Depthwise Convolution}{28}{section*.36}}
\newlabel{eq:DW_kost}{{5.3}{28}{Depthwise Convolution}{equation.5.3}{}}
\BKM@entry{id=26,dest={73756273656374696F6E2E352E33},srcline={1152}}{4265736F6E6465726520434E4E733A204269747465206E69636874206C6573656E}
\BKM@entry{id=27,dest={73756273756273656374696F6E2E352E332E31},srcline={1153}}{416C65784E6574}
\citation{AlexNet}
\citation{AlexNet}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Anwendung einer Depthwise Convolution auf ein Farbbild.\relax }}{29}{figure.caption.37}}
\newlabel{fig:Depthwise_faltung}{{25}{29}{Anwendung einer Depthwise Convolution auf ein Farbbild.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Pointwise Convolution}{29}{section*.38}}
\newlabel{eq:PT_kost}{{5.4}{29}{Pointwise Convolution}{equation.5.4}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Depthwise Separable Convolution}{29}{section*.39}}
\newlabel{eq:DSC_kost}{{5.5}{29}{Depthwise Separable Convolution}{equation.5.5}{}}
\acronymused{CNN}
\citation{AlexNet}
\citation{AlexNet}
\BKM@entry{id=28,dest={73756273756273656374696F6E2E352E332E32},srcline={1172}}{53717565657A654E6574}
\citation{SqueezeNet}
\citation{SqueezeNet}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Besondere \acsp {CNN}: \leavevmode {\color  {red}Bitte nicht lesen}}{30}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}AlexNet}{30}{subsubsection.5.3.1}}
\acronymused{ConvL}
\acronymused{PooL}
\acronymused{FCL}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{PooL}
\acronymused{PooL}
\acronymused{FCL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}SqueezeNet}{30}{subsubsection.5.3.2}}
\acronymused{ConvL}
\citation{SqueezeNet}
\citation{SqueezeNet}
\citation{SqueezeNet}
\citation{SqueezeNet}
\citation{ResNet}
\BKM@entry{id=29,dest={73756273756273656374696F6E2E352E332E33},srcline={1196}}{5863657074696F6E}
\citation{Xception}
\citation{InceptionV3}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces  AlexNet Architektur \href  {https://neurohive.io/en/popular-networks/alexnet-imagenet-classification-with-deep-convolutional-neural-networks/}{ source} \relax }}{31}{figure.caption.40}}
\newlabel{fig:AlexNet}{{26}{31}{AlexNet Architektur \href {https://neurohive.io/en/popular-networks/alexnet-imagenet-classification-with-deep-convolutional-neural-networks/}{ source} \relax }{figure.caption.40}{}}
\acronymused{ConvL}
\BKM@entry{id=30,dest={73756273756273656374696F6E2E352E332E34},srcline={1214}}{4D6F62696C654E6574}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces  SqueezeNet Architekturen \cite  {SqueezeNet} \relax }}{32}{figure.caption.41}}
\newlabel{fig:SqueezeNet}{{27}{32}{SqueezeNet Architekturen \cite {SqueezeNet} \relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Xception}{32}{subsubsection.5.3.3}}
\newlabel{Xception}{{5.3.3}{32}{Xception}{subsubsection.5.3.3}{}}
\BKM@entry{id=31,dest={73756273656374696F6E2E352E34},srcline={1224}}{416C676F726974686D656E207A7572204F7074696D696572756E6720646573204772616469656E74656E616273746965677376657266616872656E3A204F7074696D697A6572}
\BKM@entry{id=32,dest={73756273756273656374696F6E2E352E342E31},srcline={1228}}{4164617074697665204772616469656E7420416C676F726974686D205C28416461477261645C29}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces  fire\_module \cite  {SqueezeNet} \relax }}{33}{figure.caption.42}}
\newlabel{fig:fire_module}{{28}{33}{fire\_module \cite {SqueezeNet} \relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}MobileNet}{33}{subsubsection.5.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Algorithmen zur Optimierung des Gradientenabstiegsverfahren: Optimizer}{33}{subsection.5.4}}
\newlabel{Optimizer}{{5.4}{33}{Algorithmen zur Optimierung des Gradientenabstiegsverfahren: Optimizer}{subsection.5.4}{}}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}Adaptive Gradient Algorithm (AdaGrad)}{33}{subsubsection.5.4.1}}
\citation{AdaGrad}
\BKM@entry{id=33,dest={73756273756273656374696F6E2E352E342E32},srcline={1245}}{526F6F74204D65616E205371756172652050726F7061676174696F6E5C28524D5350726F705C29}
\BKM@entry{id=34,dest={73756273756273656374696F6E2E352E342E33},srcline={1255}}{4164617074697665204D6F6D656E7420457374696D6174696F6E5C284164616D5C29}
\citation{adam}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces  Xception Architektur\relax }}{34}{figure.caption.43}}
\newlabel{fig:Xception}{{29}{34}{Xception Architektur\relax }{figure.caption.43}{}}
\newlabel{adagrad}{{5.6}{34}{Adaptive Gradient Algorithm (AdaGrad)}{equation.5.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2}Root Mean Square Propagation(RMSProp)}{34}{subsubsection.5.4.2}}
\newlabel{RMSProp}{{5.7}{34}{Root Mean Square Propagation(RMSProp)}{equation.5.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces  MobileNet Architektur \relax }}{35}{figure.caption.44}}
\newlabel{fig:MobileNet}{{30}{35}{MobileNet Architektur \relax }{figure.caption.44}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.3}Adaptive Moment Estimation(Adam)}{35}{subsubsection.5.4.3}}
\newlabel{ADAM}{{5.8}{35}{Adaptive Moment Estimation(Adam)}{equation.5.8}{}}
\BKM@entry{id=35,dest={73756273656374696F6E2E352E35},srcline={1277}}{50726F626C656D206265696D20547261696E696E6720766F6E20436F6E766F6C7574696F6E616C206E6575726F6E616C65204E65747A7765726B65}
\BKM@entry{id=36,dest={73756273756273656374696F6E2E352E352E31},srcline={1278}}{4F76657266697474696E67}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Problem beim Training von Convolutional neuronale Netzwerke}{36}{subsection.5.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.1}Overfitting}{36}{subsubsection.5.5.1}}
\newlabel{Overfitting}{{5.5.1}{36}{Overfitting}{subsubsection.5.5.1}{}}
\newlabel{Data Augmentation}{{5.5.1}{36}{Data Augmentation}{section*.45}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Data Augmentation}{36}{section*.45}}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\citation{1}
\citation{2}
\citation{3}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Anwendung von \textit  {ImageDataAugmentation} \relax }}{37}{figure.caption.46}}
\newlabel{fig:ImageDataAugmentation}{{31}{37}{Anwendung von \textit {ImageDataAugmentation} \relax }{figure.caption.46}{}}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\newlabel{Dropout}{{5.5.1}{37}{Dropout}{section*.47}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Dropout}{37}{section*.47}}
\acronymused{KNN}
\AC@undonewlabel{acro:KI}
\newlabel{acro:KI}{{5.5.1}{37}{Dropout}{section*.48}{}}
\acronymused{KI}
\acronymused{CNN}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Funktionsweise von Dropout}{37}{section*.49}}
\citation{3}
\citation{3}
\citation{3}
\acronymused{NN}
\acronymused{NN}
\newlabel{fig:dropout1}{{32a}{38}{Standard neuronale Netze\relax }{figure.caption.50}{}}
\newlabel{sub@fig:dropout1}{{a}{38}{Standard neuronale Netze\relax }{figure.caption.50}{}}
\newlabel{fig:dropout2}{{32b}{38}{Netze nach Dropout\relax }{figure.caption.50}{}}
\newlabel{sub@fig:dropout2}{{b}{38}{Netze nach Dropout\relax }{figure.caption.50}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Neuronales Netz mit Dropout ausgestattet \cite  {3}.\relax }}{38}{figure.caption.50}}
\newlabel{fig:Dropout}{{32}{38}{Neuronales Netz mit Dropout ausgestattet \cite {3}.\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Verhinderung der Koadaptationen zwischen Neuronen}{38}{section*.51}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Automatische Erh\IeC {\"o}hung von Training Daten und Regelung}{38}{section*.52}}
\citation{bactchnormalisation}
\citation{LeCun}
\citation{bactchnormalisation}
\acronymused{NN}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Erh\IeC {\"o}hung des Trainingsdaten durch Dropout\relax }}{39}{figure.caption.53}}
\newlabel{fig:DropoutDataAugmentation}{{33}{39}{Erhöhung des Trainingsdaten durch Dropout\relax }{figure.caption.53}{}}
\acronymused{CNN}
\newlabel{Batch-Normalisierung}{{5.5.1}{39}{Batch-Normalisierung}{section*.54}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Batch-Normalisierung}{39}{section*.54}}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\BKM@entry{id=37,dest={73756273756273656374696F6E2E352E352E32},srcline={1366}}{44617461736574}
\bibstyle{acm}
\BKM@entry{id=38,dest={73656374696F6E2E36},srcline={1370}}{4C6974657261747572}
\bibcite{1}{1}
\newlabel{BNA}{{5.9}{40}{Batch-Normalisierung}{equation.5.9d}{}}
\acronymused{NN}
\bibcite{CNNStory}{2}
\bibcite{2}{3}
\bibcite{3}{4}
\bibcite{4}{5}
\bibcite{pruning}{6}
\bibcite{Filter Pruning}{7}
\bibcite{Automated Pruning}{8}
\bibcite{matrix quantization}{9}
\bibcite{7}{10}
\bibcite{8}{11}
\bibcite{bactchnormalisation}{12}
\bibcite{LearningRate}{13}
\bibcite{AdaGrad}{14}
\bibcite{adam}{15}
\bibcite{quantization1}{16}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.2}Dataset}{41}{subsubsection.5.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Literatur}{41}{section.6}}
\bibcite{quantizationYoni}{17}
\bibcite{kneuron}{18}
\bibcite{AlexNet}{19}
\bibcite{SqueezeNet}{20}
\bibcite{ResNet}{21}
\bibcite{Xception}{22}
\bibcite{InceptionV3}{23}
\bibcite{MobileNet}{24}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{11.8799pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{19.68687pt}
\global\@namedef{scr@dte@subsubsection@lastmaxnumwidth}{28.80675pt}
