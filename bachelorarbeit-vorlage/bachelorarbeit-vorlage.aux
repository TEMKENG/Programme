\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\BKM@entry[2]{}
\AC@reset@newl@bel
\providecommand \oddpage@label [2]{}
\babel@aux{ngerman}{}
\babel@aux{ngerman}{}
\AC@undonewlabel{acro:CNN}
\newlabel{acro:CNN}{{}{3}{Erklärung}{section*.2}{}}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\AC@undonewlabel{acro:DNN}
\newlabel{acro:DNN}{{}{5}{\list@fname }{section*.4}{}}
\acronymused{DNN}
\BKM@entry{id=1,dest={73656374696F6E2E31},srcline={133}}{41626B5C333734727A756E67737665727A656963686E6973}
\@writefile{toc}{\contentsline {section}{\numberline {1}Abk\IeC {\"u}rzungsverzeichnis}{7}{section.1}}
\newacro{PooL}[\AC@hyperlink{PooL}{PooL}]{Pooling Layer}
\newacro{NN}[\AC@hyperlink{NN}{NN}]{neuronales Netz}
\newacro{ML}[\AC@hyperlink{ML}{ML}]{Maschine Lernen}
\newacro{ConvL}[\AC@hyperlink{ConvL}{ConvL}]{Convolutional Layer}
\newacro{KI}[\AC@hyperlink{KI}{KI}]{K\IeC {\"u}nstliche Intelligenz}
\newacro{DNN}[\AC@hyperlink{DNN}{DNN}]{Tiefe neuronale Netze}
\newacro{FCL}[\AC@hyperlink{FCL}{FCL}]{Fully Connected Layer}
\newacro{CNN}[\AC@hyperlink{CNN}{CNN}]{Convolutional Neural Network}
\newacro{DSC}[\AC@hyperlink{DSC}{DSC}]{Depthwise Separable Convolution}
\newacro{KNN}[\AC@hyperlink{KNN}{KNN}]{K\IeC {\"u}nstliches neuronales Netzwerk}
\newacro{ILSVRC}[\AC@hyperlink{ILSVRC}{ILSVRC}]{ Large Scale Visual Recognition Challenge}
\BKM@entry{id=2,dest={73656374696F6E2E32},srcline={148}}{45696E6C656974756E67}
\BKM@entry{id=3,dest={73756273656374696F6E2E322E31},srcline={149}}{4D6F7469766174696F6E}
\citation{AlexNet}
\citation{prunetoprune}
\BKM@entry{id=4,dest={73756273656374696F6E2E322E32},srcline={163}}{5A69656C20646572204172626569742E}
\@writefile{toc}{\contentsline {section}{\numberline {2}Einleitung}{8}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Motivation}{8}{subsection.2.1}}
\newlabel{motivation}{{2.1}{8}{Motivation}{subsection.2.1}{}}
\AC@undonewlabel{acro:ILSVRC}
\newlabel{acro:ILSVRC}{{2.1}{8}{Motivation}{section*.5}{}}
\acronymused{ILSVRC}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Ziel der Arbeit.}{8}{subsection.2.2}}
\BKM@entry{id=5,dest={73756273656374696F6E2E322E33},srcline={168}}{41756662617520646572204172626569742E}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Aufbau der Arbeit.}{9}{subsection.2.3}}
\acronymused{CNN}
\BKM@entry{id=6,dest={73656374696F6E2E33},srcline={175}}{4772756E646C6167656E}
\BKM@entry{id=7,dest={73756273656374696F6E2E332E31},srcline={178}}{4B5C3337346E73746C69636865206E6575726F6E616C65204E65747A7765726B65}
\BKM@entry{id=8,dest={73756273756273656374696F6E2E332E312E31},srcline={179}}{4B5C3337346E73746C6963686573204E6575726F6E}
\citation{kneuron}
\BKM@entry{id=9,dest={73756273756273656374696F6E2E332E312E32},srcline={252}}{416B746976696572756E67736B617274656E5C28466561747572652D4D6170735C29}
\@writefile{toc}{\contentsline {section}{\numberline {3}Grundlagen}{10}{section.3}}
\newlabel{Grundlagen}{{3}{10}{Grundlagen}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}K\IeC {\"u}nstliche neuronale Netzwerke}{10}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}K\IeC {\"u}nstliches Neuron}{10}{subsubsection.3.1.1}}
\AC@undonewlabel{acro:KNN}
\newlabel{acro:KNN}{{3.1.1}{10}{Künstliches Neuron}{section*.6}{}}
\acronymused{KNN}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Funktionsweise eines k\IeC {\"u}nstlichen Neurons \relax }}{10}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Fneuron}{{1}{10}{Funktionsweise eines künstlichen Neurons \relax }{figure.caption.7}{}}
\AC@undonewlabel{acro:NN}
\newlabel{acro:NN}{{3.1.1}{10}{Künstliches Neuron}{section*.8}{}}
\acronymused{NN}
\acronymused{NN }
\acronymused{KNN}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Aktivierungskarten(Feature-Maps)}{10}{subsubsection.3.1.2}}
\BKM@entry{id=10,dest={73756273756273656374696F6E2E332E312E33},srcline={255}}{46696C74657273}
\BKM@entry{id=11,dest={73756273656374696F6E2E332E32},srcline={258}}{436F6E766F6C7574696F6E616C204E657572616C204E6574776F726B}
\BKM@entry{id=12,dest={73756273756273656374696F6E2E332E322E31},srcline={260}}{46656564666F7277617264}
\BKM@entry{id=13,dest={7061726167726170682E332E322E312E31},srcline={262}}{496E707574204C61796572}
\BKM@entry{id=14,dest={7061726167726170682E332E322E312E32},srcline={266}}{46616C74756E677373636869636874}
\AC@undonewlabel{acro:FCL}
\newlabel{acro:FCL}{{3.1.2}{11}{Aktivierungskarten(Feature-Maps)}{section*.9}{}}
\acronymused{FCL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Filters}{11}{subsubsection.3.1.3}}
\newlabel{Filter}{{3.1.3}{11}{Filters}{subsubsection.3.1.3}{}}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Convolutional Neural Network}{11}{subsection.3.2}}
\acronymused{CNN}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Feedforward}{11}{subsubsection.3.2.1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.1}Input Layer}{11}{paragraph.3.2.1.1}}
\newlabel{InputLayer}{{3.2.1.1}{11}{Input Layer}{paragraph.3.2.1.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.2}Faltungsschicht}{11}{paragraph.3.2.1.2}}
\newlabel{ConvL}{{3.2.1.2}{11}{Faltungsschicht}{paragraph.3.2.1.2}{}}
\acronymused{CNN}
\AC@undonewlabel{acro:ConvL}
\newlabel{acro:ConvL}{{3.2.1.2}{11}{Faltungsschicht}{section*.10}{}}
\acronymused{ConvL}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{ConvL}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Die Anzahl und Gr\IeC {\"o}\IeC {\ss }e von Filtern.}{12}{section*.11}}
\acronymused{ConvL}
\acronymused{ConvL}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Die Schrittgr\IeC {\"o}\IeC {\ss }e}{12}{section*.13}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Einfluss der Schrittgr\IeC {\"o}\IeC {\ss }e auf die Gr\IeC {\"o}\IeC {\ss }e der Feature-Maps\relax }}{13}{figure.caption.12}}
\newlabel{fig:stride1}{{3a}{13}{\emph {Schrittgröße=(1,1) } \relax }{figure.caption.12}{}}
\newlabel{sub@fig:stride1}{{a}{13}{\emph {Schrittgröße=(1,1) } \relax }{figure.caption.12}{}}
\newlabel{fig:stride2}{{3b}{13}{\emph {Schrittgröße=(2,2) } \relax }{figure.caption.12}{}}
\newlabel{sub@fig:stride2}{{b}{13}{\emph {Schrittgröße=(2,2) } \relax }{figure.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Auswirkung von Schrittgr\IeC {\"o}\IeC {\ss }e,Filtergr\IeC {\"o}\IeC {\ss }e und Padding auf Output eines $ (100, 100, 3) $ Bild.\relax }}{13}{table.caption.14}}
\newlabel{tab:Stride and filter size}{{1}{13}{Auswirkung von Schrittgröße,Filtergröße und Padding auf Output eines $ (100, 100, 3) $ Bild.\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline \textit  {Padding}.}{13}{section*.15}}
\acronymused{ConvL}
\acronymused{CNN}
\acronymused{ConvL}
\acronymused{ConvL}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{ConvL}
\BKM@entry{id=15,dest={7061726167726170682E332E322E312E33},srcline={385}}{416B746976696572756E677366756E6B74696F6E}
\pgfsyspdfmark {pgfid2}{6784065}{44835201}
\pgfsyspdfmark {pgfid3}{13026345}{44835201}
\pgfsyspdfmark {pgfid4}{7824445}{43884930}
\pgfsyspdfmark {pgfid5}{8864825}{42934659}
\pgfsyspdfmark {pgfid6}{15107105}{42934659}
\pgfsyspdfmark {pgfid7}{6784065}{41984388}
\pgfsyspdfmark {pgfid8}{9905205}{41984388}
\pgfsyspdfmark {pgfid9}{8864825}{40083846}
\pgfsyspdfmark {pgfid10}{11985965}{40083846}
\pgfsyspdfmark {pgfid11}{6784065}{39133575}
\pgfsyspdfmark {pgfid12}{13026345}{39133575}
\pgfsyspdfmark {pgfid13}{14066725}{38183304}
\pgfsyspdfmark {pgfid14}{8864825}{37233033}
\pgfsyspdfmark {pgfid15}{15107105}{37233033}
\pgfsyspdfmark {pgfid16}{28911618}{42010602}
\pgfsyspdfmark {pgfid17}{31044576}{42010602}
\pgfsyspdfmark {pgfid18}{28911618}{41034117}
\pgfsyspdfmark {pgfid19}{29977982}{41034117}
\pgfsyspdfmark {pgfid20}{28911618}{40057632}
\pgfsyspdfmark {pgfid21}{31044576}{40057632}
\pgfsyspdfmark {pgfid22}{19450952}{34824130}
\newlabel{fig:Faltungsoperation1}{{4a}{14}{Matrixdarstellung\relax }{figure.caption.16}{}}
\newlabel{sub@fig:Faltungsoperation1}{{a}{14}{Matrixdarstellung\relax }{figure.caption.16}{}}
\newlabel{fig:Faltungsoperation2}{{4b}{14}{Pixeldarstellung \relax }{figure.caption.16}{}}
\newlabel{sub@fig:Faltungsoperation2}{{b}{14}{Pixeldarstellung \relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Faltungsoperation mit einem $ 3\times 3$-Filter und Schrittgr\IeC {\"o}\IeC {\ss }e $ =3 $\relax }}{14}{figure.caption.16}}
\newlabel{fig:Faltungsoperation}{{4}{14}{Faltungsoperation mit einem $ 3\times 3$-Filter und Schrittgröße $ =3 $\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.3}Aktivierungsfunktion}{14}{paragraph.3.2.1.3}}
\newlabel{Aktivierungsfunktion}{{3.2.1.3}{14}{Aktivierungsfunktion}{paragraph.3.2.1.3}{}}
\acronymused{NN}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Bin\IeC {\"a}re Treppenfunktion\relax }}{15}{figure.caption.17}}
\newlabel{fig:Treppenfunktion}{{5}{15}{Binäre Treppenfunktion\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Lineare Funktion\relax }}{15}{figure.caption.18}}
\newlabel{fig:Lineare Funktion}{{7}{15}{Lineare Funktion\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Logistische Funktion}{15}{section*.19}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Logistische Aktivierungsfunktion:$ sigmoid(x) $.\relax }}{16}{figure.caption.20}}
\newlabel{fig:sigmoid}{{9}{16}{Logistische Aktivierungsfunktion:$ sigmoid(x) $.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Tangens Hyperbolicus}{16}{section*.21}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Tangens Hyperbolicus.\relax }}{16}{figure.caption.22}}
\newlabel{fig:tanh}{{11}{16}{Tangens Hyperbolicus.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Rectified Linear Unit}{16}{section*.23}}
\BKM@entry{id=16,dest={7061726167726170682E332E322E312E34},srcline={568}}{506F6F6C696E67204C61796572}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces ReLU Aktivierungsfunktion\relax }}{17}{figure.caption.24}}
\newlabel{fig:relu}{{13}{17}{ReLU Aktivierungsfunktion\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Leaky ReLU Funktion}{17}{section*.25}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Leaky ReLU Funktion\relax }}{17}{figure.caption.26}}
\newlabel{fig:LReLU}{{15}{17}{Leaky ReLU Funktion\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Softmax}{17}{section*.27}}
\BKM@entry{id=17,dest={7061726167726170682E332E322E312E35},srcline={694}}{4D756C74692D6C61796572205065727A657074726F6E205C2846756C6C7920436F6E6E6563746564204C617965725C29}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.4}Pooling Layer}{18}{paragraph.3.2.1.4}}
\newlabel{Pooling Layer}{{3.2.1.4}{18}{Pooling Layer}{paragraph.3.2.1.4}{}}
\AC@undonewlabel{acro:PooL}
\newlabel{acro:PooL}{{3.2.1.4}{18}{Pooling Layer}{section*.28}{}}
\acronymused{PooL}
\acronymused{ConvL}
\acronymused{PooL}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Funktionsweise der Pooling-Sicht mit Pooling\_size$ =(2,2) $ und $ Stride =2$\relax }}{18}{figure.caption.29}}
\newlabel{fig:Pooling}{{17}{18}{Funktionsweise der Pooling-Sicht mit Pooling\_size$ =(2,2) $ und $ Stride =2$\relax }{figure.caption.29}{}}
\acronymused{PooL}
\acronymused{PooL}
\acronymused{ConvL}
\acronymused{FCL}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.1.5}Multi-layer Perzeptron (Fully Connected Layer)}{18}{paragraph.3.2.1.5}}
\newlabel{FC}{{3.2.1.5}{18}{Multi-layer Perzeptron (Fully Connected Layer)}{paragraph.3.2.1.5}{}}
\acronymused{ConvL}
\acronymused{PooL}
\acronymused{FCL}
\BKM@entry{id=18,dest={73756273756273656374696F6E2E332E322E32},srcline={749}}{4261636B666F7277617264}
\BKM@entry{id=19,dest={7061726167726170682E332E322E322E31},srcline={751}}{4665686C657266756E6B74696F6E}
\acronymused{FCL}
\acronymused{NN}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Darstellung eines neuronalen Netzes \relax }}{19}{figure.caption.30}}
\newlabel{KNN}{{18}{19}{Darstellung eines neuronalen Netzes \relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Backforward}{19}{subsubsection.3.2.2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.2.1}Fehlerfunktion}{19}{paragraph.3.2.2.1}}
\newlabel{Fehlerfunktion}{{3.2.2.1}{19}{Fehlerfunktion}{paragraph.3.2.2.1}{}}
\acronymused{CNN}
\acronymused{NN}
\citation{7}
\BKM@entry{id=20,dest={7061726167726170682E332E322E322E32},srcline={769}}{4772616469656E74}
\BKM@entry{id=21,dest={7061726167726170682E332E322E322E33},srcline={773}}{4C65726E72617465}
\citation{LearningRate}
\BKM@entry{id=22,dest={7061726167726170682E332E322E322E34},srcline={779}}{4772616469656E74656E616273746965677376657266616872656E}
\newlabel{MSE}{{3.1}{20}{Fehlerfunktion}{equation.3.1}{}}
\newlabel{CE}{{3.2}{20}{Fehlerfunktion}{equation.3.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.2.2}Gradient}{20}{paragraph.3.2.2.2}}
\newlabel{Gradient}{{3.2.2.2}{20}{Gradient}{paragraph.3.2.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.2.3}Lernrate}{20}{paragraph.3.2.2.3}}
\newlabel{Lernrate}{{3.2.2.3}{20}{Lernrate}{paragraph.3.2.2.3}{}}
\acronymused{NN}
\acronymused{NN}
\citation{CNNStory}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.2.2.4}Gradientenabstiegsverfahren}{21}{paragraph.3.2.2.4}}
\newlabel{Gradientenabstiegsverfahren}{{3.2.2.4}{21}{Gradientenabstiegsverfahren}{paragraph.3.2.2.4}{}}
\acronymused{DNN}
\acronymused{DNN}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Ablauf eines Gradientenverfahrens im \ac {DNN}.}{21}{section*.31}}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Variante des Gradientenverfahrens}{21}{section*.33}}
\acronymused{NN}
\citation{CNNStory}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Ablauf der Backpropagation\relax }}{22}{figure.caption.32}}
\newlabel{fig:Backprop}{{19}{22}{Ablauf der Backpropagation\relax }{figure.caption.32}{}}
\acronymused{NN}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Stochastic Gradient descent(SGD) \cite  {CNNStory}.\relax }}{22}{algocf.1}}
\newlabel{alg:SGD}{{1}{22}{Variante des Gradientenverfahrens}{algocf.1}{}}
\citation{CNNStory}
\BKM@entry{id=23,dest={73756273656374696F6E2E332E33},srcline={896}}{446174656E735C333434747A6520756E64204269626C696F7468656B}
\BKM@entry{id=24,dest={73756273756273656374696F6E2E332E332E31},srcline={897}}{446174656E735C333434747A65}
\citation{food-101-original}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Batch Gradient descent \cite  {CNNStory}.\relax }}{23}{algocf.2}}
\newlabel{alg:BGD}{{2}{23}{Variante des Gradientenverfahrens}{algocf.2}{}}
\acronymused{NN}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Mini-Batch Stochastic Gradient descent(MSGD) \cite  {CNNStory}.\relax }}{23}{algocf.3}}
\newlabel{alg:MSGD}{{3}{23}{Variante des Gradientenverfahrens}{algocf.3}{}}
\BKM@entry{id=25,dest={73756273756273656374696F6E2E332E332E32},srcline={908}}{4269626C696F7468656B656E}
\BKM@entry{id=26,dest={73656374696F6E2E34},srcline={918}}{4B6F6D7072657373696F6E20766F6E20444E4E}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Datens\IeC {\"a}tze und Bibliothek}{24}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Datens\IeC {\"a}tze}{24}{subsubsection.3.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Bibliotheken}{24}{subsubsection.3.3.2}}
\BKM@entry{id=27,dest={73756273656374696F6E2E342E31},srcline={928}}{42657363686E656964756E6720646573204E65747A7765726B735C285072756E696E67204E6574776F726B5C29}
\acronymused{DNN}
\acronymused{DNN}
\@writefile{toc}{\contentsline {section}{\numberline {4}Kompression von \ac {DNN}}{25}{section.4}}
\newlabel{kompression}{{4}{25}{Kompression von \ac {DNN}}{section.4}{}}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Beschneidung des Netzwerks(\textit  {Pruning Network})}{25}{subsection.4.1}}
\newlabel{kom:pruning}{{4.1}{25}{Beschneidung des Netzwerks(\textit {Pruning Network})}{subsection.4.1}{}}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\citation{pruning}
\citation{Filter Pruning}
\citation{Filter Pruning}
\acronymused{DNN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\newlabel{Schwellenwert}{{4.1}{26}{Beschneidung des Netzwerks(\textit {Pruning Network})}{figure.caption.37}{}}
\acronymused{NN}
\acronymused{NN}
\acronymused{FCL}
\acronymused{ConvL}
\acronymused{CNN}
\acronymused{NN}
\citation{Filter Pruning}
\citation{Filter Pruning}
\citation{Filter Pruning}
\acronymused{DNN}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces  Netzbeschneidung w\IeC {\"a}hrend des Trainings\relax }}{27}{figure.caption.37}}
\newlabel{fig:PN}{{20}{27}{Netzbeschneidung während des Trainings\relax }{figure.caption.37}{}}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{NN}
\newlabel{eq:l_1}{{4.1}{27}{Beschneidung des Netzwerks(\textit {Pruning Network})}{equation.4.1}{}}
\citation{Automated Pruning}
\citation{pruning}
\acronymused{DNN}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Einfluss der Intensit\IeC {\"a}t des Filters auf Feature-Map\relax }}{28}{figure.caption.38}}
\newlabel{fig:Filter_Intensit\IeC {\"a}t}{{21}{28}{Einfluss der Intensität des Filters auf Feature-Map\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces  Das Beschneiden eines Filters f\IeC {\"u}hrt zum Entfernen der entsprechenden Feature-Map und der zugeh\IeC {\"o}rigen Kernel in der n\IeC {\"a}chsten Ebene \cite  {Filter Pruning}.\relax }}{28}{figure.caption.39}}
\newlabel{fig:Filter_pruning}{{22}{28}{Das Beschneiden eines Filters führt zum Entfernen der entsprechenden Feature-Map und der zugehörigen Kernel in der nächsten Ebene \cite {Filter Pruning}.\relax }{figure.caption.39}{}}
\BKM@entry{id=28,dest={73756273656374696F6E2E342E32},srcline={1012}}{5175616E746973696572756E6720766F6E206E6575726F6E616C656E204E65747A7765726B656E}
\BKM@entry{id=29,dest={73756273756273656374696F6E2E342E322E31},srcline={1015}}{4D617472697866616B746F726973696572756E67}
\acronymused{DNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Quantisierung von neuronalen Netzwerken}{29}{subsection.4.2}}
\newlabel{kom:quantization}{{4.2}{29}{Quantisierung von neuronalen Netzwerken}{subsection.4.2}{}}
\AC@undonewlabel{acro:ML}
\newlabel{acro:ML}{{4.2}{29}{Quantisierung von neuronalen Netzwerken}{section*.40}{}}
\acronymused{ML}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Matrixfaktorisierung}{29}{subsubsection.4.2.1}}
\citation{matrix quantization}
\BKM@entry{id=30,dest={73756273756273656374696F6E2E342E322E32},srcline={1041}}{5175616E746973696572756E67206D69742077656E6967657220426974735C284C6F772D626974205175616E74697A6174696F6E5C29}
\acronymused{DNN}
\newlabel{eq:SVD}{{4.2}{30}{Matrixfaktorisierung}{equation.4.2}{}}
\acronymused{NN}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Parameter Approximieren durch Matrixfaktorisierung \relax }}{30}{figure.caption.41}}
\newlabel{fig:matrix_fatorization}{{23}{30}{Parameter Approximieren durch Matrixfaktorisierung \relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Quantisierung mit weniger Bits(Low-bit Quantization)}{30}{subsubsection.4.2.2}}
\citation{quantization1}
\citation{quantizationYoni}
\citation{quantizationYoni}
\citation{quantizationYoni}
\acronymused{DNN}
\acronymused{ML}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\citation{quantizationYoni}
\BKM@entry{id=31,dest={73756273656374696F6E2E342E33},srcline={1059}}{487566666D616E20436F64696572756E67}
\BKM@entry{id=32,dest={73656374696F6E2E35},srcline={1062}}{4578706572696D656E74}
\BKM@entry{id=33,dest={73756273656374696F6E2E352E31},srcline={1064}}{416E616C797365206465722045726765626E69737365206D69742048696C666520766F6E204D657472696B656E}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Huffman Codierung}{32}{subsection.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiment}{32}{section.5}}
\newlabel{Experiment}{{5}{32}{Experiment}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Analyse der Ergebnisse mit Hilfe von Metriken}{32}{subsection.5.1}}
\acronymused{NN}
\BKM@entry{id=34,dest={73756273656374696F6E2E352E32},srcline={1085}}{456E74777572662065696E6573206E6575726F6E616C656E2046616C74756E736E65747A7765726B65733A2054656D6B694E65742E}
\BKM@entry{id=35,dest={73756273756273656374696F6E2E352E322E31},srcline={1088}}{417274206465722046616C74756E677373636869636874656E2E}
\newlabel{eq:acc}{{5.1}{33}{Analyse der Ergebnisse mit Hilfe von Metriken}{equation.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Vergleich zwischen der Genauigkeitskurve und der logarithmischen Verlustkurve. \relax }}{33}{figure.caption.42}}
\newlabel{fig:accVSlogLoss}{{24}{33}{Vergleich zwischen der Genauigkeitskurve und der logarithmischen Verlustkurve. \relax }{figure.caption.42}{}}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Entwurf eines neuronalen Faltunsnetzwerkes: TemkiNet.}{33}{subsection.5.2}}
\acronymused{CNN}
\BKM@entry{id=36,dest={7061726167726170682E352E322E312E31},srcline={1102}}{5374616E6461726420436F6E766F6C7574696F6E}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Art der Faltungsschichten.}{34}{subsubsection.5.2.1}}
\acronymused{ConvL}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.1.1}Standard Convolution}{34}{paragraph.5.2.1.1}}
\newlabel{CONV}{{5.2.1.1}{34}{Standard Convolution}{paragraph.5.2.1.1}{}}
\newlabel{eq:outputSize}{{5.2}{34}{Standard Convolution}{equation.5.2}{}}
\newlabel{eq:SF_kost}{{5.3}{34}{Standard Convolution}{equation.5.3}{}}
\BKM@entry{id=37,dest={7061726167726170682E352E322E312E32},srcline={1123}}{44657074687769736520436F6E766F6C7574696F6E}
\BKM@entry{id=38,dest={7061726167726170682E352E322E312E33},srcline={1136}}{506F696E747769736520436F6E766F6C7574696F6E}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Standardfaltungsschicht mit zwei Filtern auf ein Farbbild.\relax }}{35}{figure.caption.43}}
\newlabel{fig:Standardfaltung}{{25}{35}{Standardfaltungsschicht mit zwei Filtern auf ein Farbbild.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.1.2}Depthwise Convolution}{35}{paragraph.5.2.1.2}}
\newlabel{Depthwise}{{5.2.1.2}{35}{Depthwise Convolution}{paragraph.5.2.1.2}{}}
\newlabel{eq:DW_kost}{{5.4}{35}{Depthwise Convolution}{equation.5.4}{}}
\BKM@entry{id=39,dest={7061726167726170682E352E322E312E34},srcline={1144}}{44657074687769736520536570617261626C6520436F6E766F6C7574696F6E}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Depthwise Convolution auf ein Farbbild.\relax }}{36}{figure.caption.44}}
\newlabel{fig:Depthwise_faltung}{{26}{36}{Depthwise Convolution auf ein Farbbild.\relax }{figure.caption.44}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.1.3}Pointwise Convolution}{36}{paragraph.5.2.1.3}}
\newlabel{Pointwise}{{5.2.1.3}{36}{Pointwise Convolution}{paragraph.5.2.1.3}{}}
\newlabel{eq:PT_kost}{{5.5}{36}{Pointwise Convolution}{equation.5.5}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.1.4}Depthwise Separable Convolution}{36}{paragraph.5.2.1.4}}
\newlabel{DSC}{{5.2.1.4}{36}{Depthwise Separable Convolution}{paragraph.5.2.1.4}{}}
\newlabel{eq:DSC_kost}{{5.6}{36}{Depthwise Separable Convolution}{equation.5.6}{}}
\acronymused{CNN}
\BKM@entry{id=40,dest={73756273756273656374696F6E2E352E322E32},srcline={1153}}{46616C74656E6465206E6575726F6E616C65204E65747A7765726B65}
\BKM@entry{id=41,dest={7061726167726170682E352E322E322E31},srcline={1155}}{416C65784E6574}
\citation{AlexNet}
\citation{AlexNet}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Faltende neuronale Netzwerke}{37}{subsubsection.5.2.2}}
\newlabel{CNN}{{5.2.2}{37}{Faltende neuronale Netzwerke}{subsubsection.5.2.2}{}}
\acronymused{CNN}
\acronymused{CNN}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.2.1}AlexNet}{37}{paragraph.5.2.2.1}}
\acronymused{ConvL}
\acronymused{PooL}
\acronymused{FCL}
\acronymused{CNN}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces  AlexNet Architektur \href  {https://neurohive.io/en/popular-networks/alexnet-imagenet-classification-with-deep-convolutional-neural-networks/}{ source} \relax }}{37}{figure.caption.45}}
\newlabel{fig:AlexNet}{{27}{37}{AlexNet Architektur \href {https://neurohive.io/en/popular-networks/alexnet-imagenet-classification-with-deep-convolutional-neural-networks/}{ source} \relax }{figure.caption.45}{}}
\citation{AlexNet}
\BKM@entry{id=42,dest={7061726167726170682E352E322E322E32},srcline={1183}}{5863657074696F6E}
\citation{Xception}
\citation{InceptionV3}
\acronymused{PooL}
\acronymused{FCL}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Xception- und MobileNet-Baustein.\relax }}{38}{figure.caption.46}}
\newlabel{fig:Xception|MobileNet}{{28}{38}{Xception- und MobileNet-Baustein.\relax }{figure.caption.46}{}}
\BKM@entry{id=43,dest={7061726167726170682E352E322E322E33},srcline={1187}}{4D6F62696C654E6574}
\citation{MobileNet}
\BKM@entry{id=44,dest={7061726167726170682E352E322E322E34},srcline={1196}}{54656D6B694E6574}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.2.2}Xception}{39}{paragraph.5.2.2.2}}
\newlabel{Xception}{{5.2.2.2}{39}{Xception}{paragraph.5.2.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.2.3}MobileNet}{39}{paragraph.5.2.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces TemkiNet-Bausteine.\relax }}{39}{figure.caption.47}}
\newlabel{fig:TEMKENG_NET}{{29}{39}{TemkiNet-Bausteine.\relax }{figure.caption.47}{}}
\BKM@entry{id=45,dest={73756273756273656374696F6E2E352E322E33},srcline={1235}}{566572676C65696368207A7769736368656E20434E4E73}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.2.2.4}TemkiNet}{40}{paragraph.5.2.2.4}}
\newlabel{exp:TEMKI}{{5.2.2.4}{40}{TemkiNet}{paragraph.5.2.2.4}{}}
\acronymused{CNN}
\acronymused{NN}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces TemkiNet Architektur mit $ 101 $ Feature-Maps pro Schicht im Extratorblock. \relax }}{40}{table.caption.48}}
\newlabel{tab:Temki_Architectur}{{2}{40}{TemkiNet Architektur mit $ 101 $ Feature-Maps pro Schicht im Extratorblock. \relax }{table.caption.48}{}}
\BKM@entry{id=46,dest={73756273656374696F6E2E352E33},srcline={1253}}{4D6574686F64656E20756E64204879706572706172616D65746572207A757220566572626573736572756E6720646572204E65747A7765726B6C65697374756E672E}
\BKM@entry{id=47,dest={73756273756273656374696F6E2E352E332E31},srcline={1257}}{446174656E7665726D656872756E67205C2844617461204175676D656E746174696F6E5C292E}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Vergleich zwischen CNNs}{41}{subsubsection.5.2.3}}
\newlabel{sub:vergleich_CNN}{{5.2.3}{41}{Vergleich zwischen CNNs}{subsubsection.5.2.3}{}}
\acronymused{CNN}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Vergleich zwischen CNN.\relax }}{41}{table.caption.49}}
\newlabel{tab:vergleich_CNN}{{3}{41}{Vergleich zwischen CNN.\relax }{table.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Methoden und Hyperparameter zur Verbesserung der Netzwerkleistung.}{41}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Datenvermehrung (\textit  {Data Augmentation}).}{41}{subsubsection.5.3.1}}
\newlabel{Data Augmentation}{{5.3.1}{41}{Datenvermehrung (\textit {Data Augmentation})}{subsubsection.5.3.1}{}}
\acronymused{DNN}
\acronymused{CNN}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Anwendung von \textit  {ImageDataAugmentation}-Funktion \relax }}{42}{figure.caption.50}}
\newlabel{fig:ImageDataAugmentation}{{30}{42}{Anwendung von \textit {ImageDataAugmentation}-Funktion \relax }{figure.caption.50}{}}
\acronymused{CNN}
\BKM@entry{id=48,dest={73756273756273656374696F6E2E352E332E32},srcline={1308}}{44726F706F7574}
\citation{1}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces  Vergleich von Datenvermehrungstechniken\relax }}{43}{figure.caption.51}}
\newlabel{fig:DataAugmentation}{{31}{43}{Vergleich von Datenvermehrungstechniken\relax }{figure.caption.51}{}}
\acronymused{CNN}
\acronymused{CNN}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Vergleich zwischen CNN mit Datenvermehrung.\relax }}{43}{table.caption.52}}
\newlabel{tab:vergleich_CNN_1}{{4}{43}{Vergleich zwischen CNN mit Datenvermehrung.\relax }{table.caption.52}{}}
\citation{3}
\citation{3}
\citation{3}
\citation{3}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Dropout}{44}{subsubsection.5.3.2}}
\newlabel{Dropout}{{5.3.2}{44}{Dropout}{subsubsection.5.3.2}{}}
\acronymused{CNN}
\acronymused{NN}
\acronymused{NN}
\newlabel{fig:dropout1}{{32a}{44}{Standard neuronale Netzwerk\relax }{figure.caption.53}{}}
\newlabel{sub@fig:dropout1}{{a}{44}{Standard neuronale Netzwerk\relax }{figure.caption.53}{}}
\newlabel{fig:dropout2}{{32b}{44}{Neuronale Netzwerk nach Dropout\relax }{figure.caption.53}{}}
\newlabel{sub@fig:dropout2}{{b}{44}{Neuronale Netzwerk nach Dropout\relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Neuronales Netzwerk mit Dropout ausgestattet \cite  {3}.\relax }}{44}{figure.caption.53}}
\newlabel{fig:Dropout}{{32}{44}{Neuronales Netzwerk mit Dropout ausgestattet \cite {3}.\relax }{figure.caption.53}{}}
\BKM@entry{id=49,dest={73756273756273656374696F6E2E352E332E33},srcline={1359}}{416B746976696572756E677366756E6B74696F6E2E}
\acronymused{NN}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Erh\IeC {\"o}hung des Trainingsdaten durch Dropout\relax }}{45}{figure.caption.54}}
\newlabel{fig:DropoutDataAugmentation}{{33}{45}{Erhöhung des Trainingsdaten durch Dropout\relax }{figure.caption.54}{}}
\acronymused{CNN}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Anwendung von Dropout Technik.\relax }}{45}{table.caption.55}}
\newlabel{tab:dropout}{{5}{45}{Anwendung von Dropout Technik.\relax }{table.caption.55}{}}
\BKM@entry{id=50,dest={73756273756273656374696F6E2E352E332E34},srcline={1376}}{4F7074696D69657265722E}
\citation{AdaGrad}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Aktivierungsfunktion.}{46}{subsubsection.5.3.3}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces  Vergleich der Aktivierungsfunktionen.\relax }}{46}{table.caption.56}}
\newlabel{tab:Aktivierungsfunktion}{{6}{46}{Vergleich der Aktivierungsfunktionen.\relax }{table.caption.56}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Optimierer.}{46}{subsubsection.5.3.4}}
\newlabel{Optimizer}{{5.3.4}{46}{Optimierer}{subsubsection.5.3.4}{}}
\acronymused{CNN}
\newlabel{adagrad}{{5.7}{46}{Optimierer}{equation.5.7}{}}
\citation{adam}
\newlabel{RMSProp}{{5.8}{47}{Optimierer}{equation.5.8}{}}
\newlabel{Adam}{{3}{47}{Optimierer}{Item.12}{}}
\newlabel{ADAM}{{5.9}{47}{Optimierer}{equation.5.9}{}}
\BKM@entry{id=51,dest={73756273756273656374696F6E2E352E332E35},srcline={1448}}{42617463682D4E6F726D616C6973696572756E675C28424E5C292E}
\citation{bactchnormalisation}
\citation{bactchnormalisation}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Vergleich zwischen Optimierern\relax }}{48}{table.caption.57}}
\newlabel{tab:Optimierer}{{7}{48}{Vergleich zwischen Optimierern\relax }{table.caption.57}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5}Batch-Normalisierung(BN).}{48}{subsubsection.5.3.5}}
\newlabel{Batch-Normalisierung}{{5.3.5}{48}{Batch-Normalisierung(BN)}{subsubsection.5.3.5}{}}
\acronymused{NN}
\acronymused{NN}
\acronymused{NN}
\BKM@entry{id=52,dest={73756273756273656374696F6E2E352E332E36},srcline={1484}}{42696C6467725C3336365C333337652E}
\BKM@entry{id=53,dest={73756273756273656374696F6E2E352E332E37},srcline={1513}}{416E7A61686C2064657220416B746976696572756E67736B617274656E2070726F20536368696368743A}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Batch-Normalisierung-Algorithmus \cite  {bactchnormalisation}.\relax }}{49}{algocf.4}}
\newlabel{alg:bactchnormalisation}{{4}{49}{Batch-Normalisierung(BN)}{algocf.4}{}}
\acronymused{NN}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Einfluss der Batch-Normalisierung auf \textit  {TemkiNet.}\relax }}{49}{table.caption.59}}
\newlabel{tab:batchnormalisierung}{{8}{49}{Einfluss der Batch-Normalisierung auf \textit {TemkiNet.}\relax }{table.caption.59}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.6}Bildgr\IeC {\"o}\IeC {\ss }e.}{49}{subsubsection.5.3.6}}
\BKM@entry{id=54,dest={73756273756273656374696F6E2E352E332E38},srcline={1535}}{5175616C69745C333434742064657320446174656E7361747A6573}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Einfluss der Bildgr\IeC {\"o}\IeC {\ss }e auf die Netzleistung.\relax }}{50}{table.caption.60}}
\newlabel{tab:Bildqualtaet}{{9}{50}{Einfluss der Bildgröße auf die Netzleistung.\relax }{table.caption.60}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.7}Anzahl der Aktivierungskarten pro Schicht:}{50}{subsubsection.5.3.7}}
\acronymused{ConvL}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Einfluss der Anzahl von Neuronen pro Schicht.\relax }}{50}{table.caption.61}}
\newlabel{tab:units}{{10}{50}{Einfluss der Anzahl von Neuronen pro Schicht.\relax }{table.caption.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Einfluss der Anzahl von Neuronen pro Schicht.\relax }}{50}{figure.caption.62}}
\newlabel{fig:units}{{34}{50}{Einfluss der Anzahl von Neuronen pro Schicht.\relax }{figure.caption.62}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.8}Qualit\IeC {\"a}t des Datensatzes}{51}{subsubsection.5.3.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Problem mit Datens\IeC {\"a}tzen.\relax }}{51}{figure.caption.63}}
\newlabel{fig:Dataset_problem}{{35}{51}{Problem mit Datensätzen.\relax }{figure.caption.63}{}}
\BKM@entry{id=55,dest={73756273756273656374696F6E2E352E332E39},srcline={1566}}{45696E666C75737320646572204C65726E72617465}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Einfluss der Qualit\IeC {\"a}t des Datensatzes \relax }}{52}{table.caption.64}}
\newlabel{tab:Bildqualitaet}{{11}{52}{Einfluss der Qualität des Datensatzes \relax }{table.caption.64}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.9}Einfluss der Lernrate}{52}{subsubsection.5.3.9}}
\newlabel{Experiment:Lernrate}{{5.3.9}{52}{Einfluss der Lernrate}{subsubsection.5.3.9}{}}
\acronymused{CNN}
\acronymused{CNN}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Einfluss der Lernrate auf ein $ (224,224,3) $Bild.\relax }}{53}{figure.caption.65}}
\newlabel{fig:Lernrate}{{36}{53}{Einfluss der Lernrate auf ein $ (224,224,3) $Bild.\relax }{figure.caption.65}{}}
\acronymused{NN}
\BKM@entry{id=56,dest={73756273656374696F6E2E352E34},srcline={1626}}{56657272696E676572756E672064657320537065696368657262656461726673}
\BKM@entry{id=57,dest={73756273756273656374696F6E2E352E342E31},srcline={1628}}{45787472656D652056657273696F6E20766F6E2054656D6B694E65742E}
\newlabel{fig:Lernrate_schedulera}{{37a}{54}{\relax }{figure.caption.66}{}}
\newlabel{sub@fig:Lernrate_schedulera}{{a}{54}{\relax }{figure.caption.66}{}}
\newlabel{fig:Lernrate_schedulerb}{{37b}{54}{\relax }{figure.caption.66}{}}
\newlabel{sub@fig:Lernrate_schedulerb}{{b}{54}{\relax }{figure.caption.66}{}}
\newlabel{fig:Lernrate_schedulerc}{{37c}{54}{\relax }{figure.caption.66}{}}
\newlabel{sub@fig:Lernrate_schedulerc}{{c}{54}{\relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces Lernraten-Scheduler.\relax }}{54}{figure.caption.66}}
\newlabel{fig:Lernrate_scheduler}{{37}{54}{Lernraten-Scheduler.\relax }{figure.caption.66}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Verringerung des Speicherbedarfs}{54}{subsection.5.4}}
\newlabel{Exp:Speicher}{{5.4}{54}{Verringerung des Speicherbedarfs}{subsection.5.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}Extreme Version von \textit  {TemkiNet.}}{54}{subsubsection.5.4.1}}
\newlabel{Extrem}{{5.4.1}{54}{Extreme Version von \textit {TemkiNet.}}{subsubsection.5.4.1}{}}
\BKM@entry{id=58,dest={73756273756273656374696F6E2E352E342E32},srcline={1706}}{5072756E696E67}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces \textit  {TemkiNet} Extratorblock von einigen Extremversion mit $ 101 $ Feature-Maps pro \ac {ConvL}\relax }}{55}{table.caption.67}}
\acronymused{ConvL}
\newlabel{tab:Temki_Architectur1}{{12}{55}{\textit {TemkiNet} Extratorblock von einigen Extremversion mit $ 101 $ Feature-Maps pro \ac {ConvL}\relax }{table.caption.67}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces  Klassifikationsblocks von \textit  {TemkiNet} Varianten\relax }}{55}{table.caption.68}}
\newlabel{tab:Temki_Architectur 1}{{13}{55}{Klassifikationsblocks von \textit {TemkiNet} Varianten\relax }{table.caption.68}{}}
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Variante von \textit  {TemkiNet.}\relax }}{55}{table.caption.69}}
\newlabel{tab:Bildqualitaetf}{{14}{55}{Variante von \textit {TemkiNet.}\relax }{table.caption.69}{}}
\BKM@entry{id=59,dest={73756273756273656374696F6E2E352E342E33},srcline={1733}}{5175616E746973696572756E67}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.2}Pruning}{56}{subsubsection.5.4.2}}
\newlabel{exp:pruning}{{5.4.2}{56}{Pruning}{subsubsection.5.4.2}{}}
\acronymused{CNN}
\acronymused{CNN}
\acronymused{CNN}
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces Pruning von CNN\relax }}{56}{table.caption.70}}
\newlabel{tab:pruning}{{15}{56}{Pruning von CNN\relax }{table.caption.70}{}}
\BKM@entry{id=60,dest={73756273656374696F6E2E352E35},srcline={1776}}{5472616E736665722D4C65726E656E205C285472616E73666572204C6561726E696E675C29}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.3}Quantisierung}{57}{subsubsection.5.4.3}}
\@writefile{lot}{\contentsline {table}{\numberline {16}{\ignorespaces Quantisierung von CNN\relax }}{57}{table.caption.71}}
\newlabel{tab:Quantisierung}{{16}{57}{Quantisierung von CNN\relax }{table.caption.71}{}}
\@writefile{lot}{\contentsline {table}{\numberline {17}{\ignorespaces Quantisierung mit TensorRT von Nvidia\relax }}{58}{table.caption.72}}
\newlabel{tab:Quantisierung TensorRT}{{17}{58}{Quantisierung mit TensorRT von Nvidia\relax }{table.caption.72}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Transfer-Lernen (\textit  {Transfer Learning})}{58}{subsection.5.5}}
\newlabel{Exp:Transfer-Lernen}{{5.5}{58}{Transfer-Lernen (\textit {Transfer Learning})}{subsection.5.5}{}}
\acronymused{CNN}
\acronymused{CNN}
\BKM@entry{id=61,dest={73656374696F6E2E36},srcline={1802}}{5A7573616D6D656E66617373756E6720756E6420417573626C69636B}
\BKM@entry{id=62,dest={73756273656374696F6E2E362E31},srcline={1803}}{5A7573616D6D656E66617373756E67}
\@writefile{lot}{\contentsline {table}{\numberline {18}{\ignorespaces Transfer Lernen.\relax }}{59}{table.caption.73}}
\newlabel{exp:TL}{{18}{59}{Transfer Lernen.\relax }{table.caption.73}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Zusammenfassung und Ausblick}{59}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Zusammenfassung}{59}{subsection.6.1}}
\acronymused{ConvL}
\acronymused{PooL}
\acronymused{FCL}
\acronymused{CNN}
\BKM@entry{id=63,dest={73756273656374696F6E2E362E32},srcline={1820}}{417573626C69636B}
\citation{AlexNet}
\citation{ZeRo}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Ausblick}{60}{subsection.6.2}}
\bibstyle{acm}
\bibcite{prunetoprune}{1}
\bibcite{1}{2}
\bibcite{CNNStory}{3}
\bibcite{2}{4}
\bibcite{3}{5}
\bibcite{4}{6}
\bibcite{pruning}{7}
\bibcite{Filter Pruning}{8}
\bibcite{Automated Pruning}{9}
\bibcite{matrix quantization}{10}
\bibcite{7}{11}
\bibcite{8}{12}
\bibcite{bactchnormalisation}{13}
\bibcite{LearningRate}{14}
\bibcite{AdaGrad}{15}
\bibcite{adam}{16}
\bibcite{quantization1}{17}
\bibcite{quantizationYoni}{18}
\bibcite{kneuron}{19}
\bibcite{AlexNet}{20}
\bibcite{SqueezeNet}{21}
\bibcite{ResNet}{22}
\bibcite{Xception}{23}
\bibcite{InceptionV3}{24}
\bibcite{MobileNet}{25}
\bibcite{food-101-original}{26}
\bibcite{ZeRo}{27}
\citation{Filter Pruning}
\citation{3}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{11.8799pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{19.68687pt}
\global\@namedef{scr@dte@subsubsection@lastmaxnumwidth}{28.80675pt}
\global\@namedef{scr@dte@paragraph@lastmaxnumwidth}{37.92662pt}
\global\@namedef{scr@dte@figure@lastmaxnumwidth}{16.43492pt}
