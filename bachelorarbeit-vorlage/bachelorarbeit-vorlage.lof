\babel@toc {ngerman}{}
\babel@toc {ngerman}{}
\contentsline {figure}{\numberline {1}{\ignorespaces Funktionsweise eines k\IeC {\"u}nstlichen Neurons \relax }}{5}{figure.caption.6}
\contentsline {figure}{\numberline {2}{\ignorespaces Faltungsoperation mit einem $ 3\times 3 -$Filter und Schrittgr\IeC {\"o}\IeC {\ss }e $ =1 $\relax }}{8}{figure.caption.10}
\contentsline {figure}{\numberline {3}{\ignorespaces Faltungsoperation mit einem $ 3\times 3 -$Filter und Schrittgr\IeC {\"o}\IeC {\ss }e $ =2 $\relax }}{8}{figure.caption.11}
\contentsline {figure}{\numberline {4}{\ignorespaces Bin\IeC {\"a}re Treppenfunktion\relax }}{9}{figure.caption.12}
\contentsline {figure}{\numberline {6}{\ignorespaces Lineare Funktion\relax }}{9}{figure.caption.13}
\contentsline {figure}{\numberline {8}{\ignorespaces Logistische Aktivierungsfunktion:$ sigmoid(x) $.\relax }}{10}{figure.caption.14}
\contentsline {figure}{\numberline {10}{\ignorespaces Tangens Hyperbolicus.\relax }}{10}{figure.caption.15}
\contentsline {figure}{\numberline {12}{\ignorespaces ReLU Aktivierungsfunktion\relax }}{11}{figure.caption.16}
\contentsline {figure}{\numberline {14}{\ignorespaces Leaky ReLU Funktion\relax }}{11}{figure.caption.17}
\contentsline {figure}{\numberline {16}{\ignorespaces Funktionsweise eines Max-Pooling-Layer\relax }}{12}{figure.caption.18}
\contentsline {figure}{\numberline {17}{\ignorespaces Funktionsweise eines Average-Pooling-Layer \relax }}{12}{figure.caption.20}
\contentsline {figure}{\numberline {18}{\ignorespaces Darstellung eines neuronalen Netzes \relax }}{13}{figure.caption.21}
\contentsline {figure}{\numberline {19}{\ignorespaces Ablauf der Backpropagation\relax }}{16}{figure.caption.22}
\contentsline {figure}{\numberline {20}{\ignorespaces Ablauf der Netzbeschneidung (\textit {Pruning Network})\relax }}{19}{figure.caption.26}
\contentsline {figure}{\numberline {21}{\ignorespaces Anwendung von \textit {ImageDataAugmentation} \relax }}{22}{figure.caption.27}
\contentsline {figure}{\numberline {22}{\ignorespaces Neuronales Netz mit Dropout ausgestattet \cite {3}.\relax }}{23}{figure.caption.29}
\contentsline {figure}{\numberline {23}{\ignorespaces Erh\IeC {\"o}hung des Trainingsdaten durch Dropout\relax }}{24}{figure.caption.30}
\contentsline {figure}{\numberline {24}{\ignorespaces AlexNet Architektur \href {https://neurohive.io/en/popular-networks/alexnet-imagenet-classification-with-deep-convolutional-neural-networks/}{ zum Bild} \relax }}{27}{figure.caption.31}
\contentsline {figure}{\numberline {25}{\ignorespaces SqueezeNet Architekturen \cite {SqueezeNet} \relax }}{28}{figure.caption.32}
\contentsline {figure}{\numberline {26}{\ignorespaces fire\_module \cite {SqueezeNet} \relax }}{29}{figure.caption.33}
\contentsline {figure}{\numberline {27}{\ignorespaces Xception Architektur\relax }}{29}{figure.caption.34}
\contentsline {figure}{\numberline {28}{\ignorespaces MobileNet Architektur \relax }}{30}{figure.caption.35}
