
\documentclass[12pt,a4paper]{scrartcl}

% scrartcl ist eine abgeleitete Artikel-Klasse im Koma-Skript
% zur Kontrolle des Umbruchs Klassenoption draft verwenden


% die folgenden Packete erlauben den Gebrauch von Umlauten und ß
% in der Latex Datei
\usepackage[utf8]{inputenc}
% \usepackage[latin1]{inputenc} %  Alternativ unter Windows
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{url}

\usepackage[pdftex]{graphicx}
\usepackage{latexsym}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{ae,aecompl}
\usepackage{blindtext}
\setcounter{secnumdepth}{5}
%\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage{hyperref}
\usepackage{acronym}
\usepackage{subcaption}
\usepackage[dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage{tkz-euclide}
\usepackage{pgfplots}
\usetikzlibrary{matrix, positioning}

%\usepackage[demo]{graphicx}
\usetikzlibrary{arrows,automata, matrix,chains,positioning,decorations.pathreplacing,arrows}

% Abstand obere Blattkante zur Kopfzeile ist 2.54cm - 15mm
\setlength{\topmargin}{-15mm}


\numberwithin{equation}{section} 

% einige Abkuerzungen
\newcommand{\C}{\mathbb{C}} % komplexe
\newcommand{\K}{\mathbb{K}} % komplexe
\newcommand{\R}{\mathbb{R}} % reelle
\newcommand{\Q}{\mathbb{Q}} % rationale
\newcommand{\Z}{\mathbb{Z}} % ganze
\newcommand{\N}{\mathbb{N}} % natuerliche
\def\Arrow{\raisebox{3\height}{\scalebox{1}{$\xRightarrow[.]{.}$}}}


\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
	{-2.5ex\@plus -1ex \@minus -.25ex}%
	{1.25ex \@plus .25ex}%
	{\normalfont\normalsize\bfseries}}
\makeatother
\setcounter{secnumdepth}{4} % how many sectioning levels to assign numbers to
\setcounter{tocdepth}{4}    % how many sectioning levels to show in ToC

\begin{document}
  % Keine Seitenzahlen im Vorspann
  \pagestyle{empty}

  % Titelblatt der Arbeit
  \begin{titlepage}

    \includegraphics[scale=0.05]{logo_uni} 
    \vspace*{2cm} 

 \begin{center} \large 
    
    Bachelorarbeit
    \vspace*{2cm}

    {\huge Titel der Bachelorarbeit: Image Analysis for Food Safety and Health}
    \vspace*{2.5cm}

    Name des Autors: TEMKENG Thibaut
    \vspace*{1.5cm}

    Datum der Abgabe: Ende Oktober
    \vspace*{4.5cm}


    Betreuung: Name der Betreuer/ des Betreuers:Shou Liu \\[1cm]
    Fakultät für Embedded Intelligence for Health Care and Wellbeing \\[1cm]

  \end{center}
\end{titlepage}



  % Inhaltsverzeichnis
  \tableofcontents
  \listoffigures

\newpage
 


  % Ab sofort Seitenzahlen in der Kopfzeile anzeigen
  \pagestyle{headings}

\section{Einleitung}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \newpage  % neuer Abschnitt auf neue Seite, kann auch entfallen
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
\section{Grundlagen}\label{Grundlaagen}
\subsection{Neuron}
Ein künstliches Neuron\cite{kneuron} ist eine mathematische Funktion, die das biologische Neuron nachbildet. Künstliche Neuronen sind elementare Einheiten in einem \ac{KNN}. Das künstliche Neuron empfängt einen oder mehrere Inputs und bildet sie auf einen Output ab. Normalerweise wird jeder Eingabe $ x_i $ separat mit einem Gewicht $ w_i $ multipliziert und danach aufsummiert und zum Schluss wird die Summe durch eine Funktion geleitet, die als Aktivierungs- oder Übertragungsfunktion bekannt ist.Eine schematische Darstellung eines künstlichen Neurons ist in Abbildung \ref{fig:Fneuron}
zu sehen.

\begin{figure}[h]
	\centering
	\begin{tikzpicture}[
	init/.style={
		draw,
		rectangle, rounded corners,
		font=\Large,
		inner sep=2pt,
		join = by -latex
	},
	squa/.style={
		draw,
		inner sep=2pt,
		font=\Large,
		join = by -latex
	},
	start chain=2,node distance=13mm
	]
	\node[on chain=2] 
	(x2) {\textbf{$x_j$}};
	\node[on chain=2,join=by o-latex] 
	{\textbf{$w_j$}};
	\node[on chain=2,init] (sigma) 
	{$z= \sum_{i =1}^{n}{x_iw_i +b} $};
	\node[on chain=2,squa,label=above:{\parbox{2cm}{\centering Aktivierungs\\funktion }}]   
	{$f(z)$};
	\node[on chain=2,label=above:Output,join=by -latex] 
	{$y$};
	\begin{scope}[start chain=1]
	\node[on chain=1] at (0,1.5cm) 
	(x1) {\textbf{$x_1$}};
	\node[on chain=1,join=by o-latex] 
	(w1) {$w_1$};
	\end{scope}
	\begin{scope}[start chain=3]
	\node[on chain=3] at (0,-1.5cm) 
	(x3) {$x_n$};
	\node[on chain=3,label=below:Gewichte,join=by o-latex] 
	(w3) {$w_n$};
	\end{scope}
	\begin{scope}[start chain=4]
	\node[on chain=4] at (0,-.75cm) 
	(x4) {\vdots};
	\node[on chain=4,join=by o-latex] 
	(w4) {\vdots};
	\end{scope}
	
	\begin{scope}[start chain=5]
	\node[on chain=5] at (0,.75cm) 
	(x5) {\vdots};
	\node[on chain=5,join=by o-latex] 
	(w5) {\vdots};
	\end{scope}
	\node[label=above:{\parbox{2cm}{\centering Bias\\b }}]  (b)[above =0.7cm and 4cm of sigma] {};
	
	\draw[-latex] (w1) -- (sigma);
	\draw[-latex] (w3) -- (sigma);
	\draw[-latex] (w4) -- (sigma);
	\draw[-latex] (w5) -- (sigma);
	\draw[o-latex] (b) -- (sigma);
	
	\draw[decorate,decoration={brace,mirror}] (x1.north west) -- node[left=10pt] {Inputs} (x3.south west);
	\end{tikzpicture}
	\caption{Funktionsweise eines künstlichen Neurons }
	\label{fig:Fneuron}
\end{figure}

Künstliche Neurone können aufgestapelt werden, um eine Schicht(\textit{Layer}) zu bilden.Ein \ac{KNN} besteht aus einer oder mehreren Schichten und je nach seiner Position in einem \ac{NN} wird eine Schicht anders genannt: Eingangsschicht(\textit{Input Layer}) bzw. Ausgabeschicht(\textit{Output Layer}), wenn das Layer die Eingangsdaten bzw. Ausgabedaten des neuronalen Netzes darstellt und versteckte Schicht(\textit{Hidden Layer}), wenn es keine Eingang- oder Ausgabeschicht ist.Ein kurzer Überblick über die Darstellung von \acsp{KNN} kann sich in Abbildung \ref{KNN} verschafft werden.

\subsection{Merkmalskarten(Feature-Maps)}
Die Ausgabe einer Schicht wird als Aktivierungskarten oder Feature-Map(s) bezeichnet. Die Anzahl von Feature-Maps in einer Schicht ist gleich die Anzahl der Ausgabekanäle(\textit{output channels}) bzw: Tiefe(\textit{depth}) dieser Schicht.
In einer Faltungsschicht ist ein Feature-Map immer zweidimensional, während die Dimension eines Feature-Maps in einem \ac{FCL} nur von der des Inputs abhängt, genauer gesagt,für ein n-dimensionales Inputs ist ein Feature-Map $ (n-1) $dimensional.
Wie die Feature-Maps berechnet werden, hängt sehr vom Schichttyp ab. Es wird beispielsweise in einer Faltungsschicht die Faltungsoperation mehrmals auf die Eingabe angewendet und jedes Mal wird ein neues Feature-Map erhalten.

\subsection{Filters}\label{Filter}
Filter ermöglicht die Extraktion von Features 


\begin{itemize}
	%- formalisierte Entsprechung der Nervenzelle besteht aus\\
	
	%	\item \textbf{Aktivierungszustand} (\textit{Activation state}) Er gibt oder definiert den aktuellen Zustand eines Neurons.
	%	\item \textbf{Propagierungsfunktion} (\textit{propagation function}) Sie bestimmt den gesamten Input(auch Netto-Input) des Neurons.\textcolor{red}{Sie legt fest, wie die Eingabe des Neuron aufzuarbeiten ist} Die häufigste verwendete Propagierungsfunktion ist die summe der gewichteten Eingaben, die das Neuron von anderen Neuronen erhält.
	%	\item \textbf{Aktivierungsfunktion} ( \textit{activation function}) Sie legt fest, wie der nächste Aktivierungszustand des Neurons aus dem Netto-Input und dem aktuellen Aktivierungszustand berechnet wird. Es gibt  zahlreiche Aktivierungsfunktionen(zB. ELU, LeakyReLU, Sigmoid, Softmax, Maxout, tanh), die auch unterschiedliche Einflüsse auf die Ausgabe eines Neurons. Die verbreitetsten Aktivierungsfunktionen sind die Logistische(Sigmoid, Gleichung \ref{Sigmoid}, Graph \ref{fig:sigmoid}), \textbf{Re}ctified \textbf{l}inear \textbf{u}nit(ReLU, Gleichung \ref{Relu}, Graph\ref{fig:relu},) Relu und Softmax(Gleichung \ref{Sotfmax})  Funktion. 
	%	
	%		\begin{equation}
	%	\label{Relu}
	%	ReLU = max(x, 0)
	%	\end{equation}
	%	
	%	\begin{equation}
	%	\label{Sigmoid}
	%	Sigmoid(x) =  \frac{\mathrm{e^x} }{\mathrm{e^x +1} }
	%	\end{equation}
	%	
	%	\begin{equation}
	%	\label{Sotfmax}
	%	Softmax(x_1, x_2, \cdots, x_n) = \frac{(e^{x_1}, ê^{x_2}, \cdots, e^{x_n})}{\sum_{i =1}^{n}{e^{x_i}}}
	%	\end{equation}
	%	
	%	
	%	Nach \cite{9} sollten die Aktivierungsfunktionen vorgezogen werden, die mehr von folgenden Eigenschaften aufweisen:	
	%	
	%	\textbf{Nichtlinearität:} Bei einem mehrschichtigen Netz ist es nicht sinnvoll eine lineare Aktivierungsfunktion zu benutzen, denn ein solches Netz in ein einschichtiges Netz immer überführt werden kann und es ist bekannt, dass ein mehrschichtiges Netz mehr als ein einschichtiges Netz leisten kann.
	%
	%	\textbf{Überall differenzierbar:} Diese Eigenschaft ermöglicht, gradientenbasierende Optimierungsverfahren zu verwenden.
	%	
	%	\textbf{Wertebereich:} Die gradientenbasierende Lernmethode ist stabiler, wenn der Wertebereich der Aktivierungsfunktion endlich ist und wenn es dagegen unendlich ist, ist das Lernen im Allgemeinen effektiver.
	%	
	%	\textbf{Monotonie:} Wenn die Aktivierungsfunktion monoton ist, so ist die Fehleroberfläche eines einschichtigen Netz immer konvex,\textcolor{red}{was bedeutet, dass es nur ein optimales Minimum gibt und das Optimierungsverfahren immer besser wird}.
	%	
	%	\textbf{Identität in 0} ( $ {\displaystyle f(x)\approx x} $ wenn  $ {\displaystyle x\approx 0} $): Diese Eigenschaft ermöglicht einen schnellen Training, wenn die Gewichte zufällig initialisiert sind und wenn die Aktivierungsfunktion in der Nähe von Null nicht gegen die Identität konvergiert, muss bei der Initialisierung der Gewichte besonders sorgfältig vorgegangen werden.
	%	
	%	
	%	\textbf{ Sigmoid-Aktivierungsfunktion} Obwohl die Sigmoid-Funktion leicht anwendbar und differenzierbar ist, wird sie nach und nach auch nicht mehr verwendet, denn sie zum Beispiel das Problem des verschwindenden Gradienten(\textit{vanishing gradient problem}) nicht löst, was die Leistung tiefer neuronaler Netze stark beeinträchtigt und sie konvergiert sehr langsam.
	\item  
\end{itemize}

\subsection{Entwicklung von Künstlichen Neuronalen Netzen } \label{Entwicklung}

%\textbf{\ac{CNN} Vorteile ca va plutôt en haut}\\ 
%Die Verwendung von \acsp{ConvL} ermöglicht die Erkennung und die Entnahme relevanter Merkmale aus den Netzeingangsdaten, was eine Vorverarbeitung der Netzeingangsdaten vermeidet. \acsp{ConvL} machen \acsp{CNN} robuster, denn obwohl es Rauschen in den Eingangsdaten gibt, schafft es immer noch die relevanten Informationen zu extrahieren.Zusätzlich sind \ac{ConvL}  gegenüber Veränderungen, die den Inhalt der Daten nicht ändern, unempfindlich, also wird ein Bild immer gleich klassifiziert werden, obwohl es z.B rotiert oder ein Bisschen verschoben ist.Ein anderer Hauptvorteil von \ac{ConvL} ist die deutliche Reduzierung der Speicheranforderung im Vergleich mit \acsp{FCL} 
%\\textbf{künstliches Neuron}.\\


\section{Convolutional Neural Network}
\subsection{Feedforward }
%\paragraph{Layer in \ac{CNN}}
\subsubsection{Input Layer}\label{InputLayer}
Die Eingangsschicht stellt die Eingangsdaten dar. Hier müssen die Eingangsdaten dreidimensional sein.Also die Eingangsdaten von \ac{CNN}  haben immer die folgende Form $ W\times H\times D $ wobei $ (W, H) $ der räumlichen Dimension und $ D $ die Tiefe der Daten entspricht. Z.B  $ 100\times100 \times3 $ für ein RGB-Bild und $ 224\times224\times1 $ für ein Graustufenbild.


\subsubsection{Faltungsschicht}\label{ConvL}
Die wichtigste Sicht bzw: der Hauptschicht in einem \ac{CNN} ist die Faltungsschicht(\emph{Convolution Layer}).
Die Eingabedaten eines \ac{CNN} besteht auf jedenfalls aus wichtigen und unwichtigen Informationen.Als wichtige und unwichtige Informationen haben wir z.B die starke Präsenz der weißen Farbe in einer Muschelsuppe bzw. die Präsenz eines Menschen, wenn man verschieden Ernährungsklasse klassifizieren möchte. Während des Trainings eines \ac{CNN} wird versucht, diese relevanten Informationen aus den Daten zu entnehmen und die irrelevanten auszuschließen. Alles was ein \ac{CNN} aus den Eingabedaten nutzt, um die Daten zu bestimmter Klassen zuzuordnen, wird als Feature bezeichnet.
Das einzige bzw. das Hauptziel einer Faltungsschicht besteht darin, die Features aus seinen Inputdaten herauszuziehen.
Dass ein Faltungsschicht in der Lage ist, Features selbst zu extrahieren, ohne dass man sie hinweist, was wichtig ist und was nicht, ist wirklich beeindruckend,Aber die Art und Weise, wie sie es tut, ist noch beeindruckender.

In einem \ac{ConvL} wird die sogenannte Faltungsoperation(\emph{convolution operation}) durchgeführt,dabei wird das komponentenweises Produkt(\textit{Hadamard-Product}) zwischen einem kleinen Bereich der Eingabedaten und einem Kernel durchgeführt und dann die ganze aufsummiert. Eine Illustration der Faltungsoperation ist in der Abbildung \ref{fig:Faltungsoperation1} zu sehen. Die Resultante der Faltungsoperation wird die Aktivierung des Neurons genannt.Sollte diese Aktivierung des Neurons null sein, dann sagt man, dass das Neuron "\textit{nicht aktiv}"{} ist und sonst ist es \textit{aktiv}.Die null Aktivierung bedeutet, dass das vom Filter gesuchte Feature nicht gefunden wurde. Je stärker oder größer die Aktivierung eines Neurons ist, desto höher ist die Wahrscheinlichkeit, dass das vom Filter gesuchte Feature gefunden ist(siehe Abbildung \ref{fig:Faltungsoperation}).
um diese Faltungsoperation durchzuführen, muss einigen Hyperparameter vordefiniert sein, und zwar:

\begin{itemize}
	\item \textbf{Anzahl und Größe von Filtern}\\
	Die Anzahl an Filters gibt nicht nur an, wie viele Filter in dem \ac{ConvL} verwendet werden, sondern auch ,wie oft die  Faltungsoperation durchgeführt wird, d.h die Anzahl der Feature-Maps oder die Tiefe der Schicht.
	Anstatt das ganze Bild zu betrachten, wenn man auf der Suche nach einem Feature ist, was mit der Tatsache gleichbedeutend ist, dass jedes Neuron der Schicht mit allen Neuronen der vorherigen verbunden ist, wird nur einen lokalen Bereich des Bildes betrachtet, wir verbinden also jedes Neuron nur mit einem lokalen Bereich der Bild. Dieser lokaler Bereich wird als Empfangsfeld(\emph{receptive field}) des Neurons bezeichnet und entspricht der Filtergröße.Es ist zu beachten, dass die Filtergröße nur der räumlichen Dimension des Filters entspricht. Die Tiefe des Filters ist gleich die vom Input, also für ein $ (100, 100, 3) $ Bild haben alle Filter die Tiefe $ 3 $.	
	Die Verwendung von solchen kleinen Filtern ist die Hauptidee hinter einer Faltungschicht. Filter haben im Allgemein eine kleine räumliche Dimension wie z.B $ 2\times 2 $, $3 \times3 $  oder  $5 \times 5$, sonst verliert man einen großen Vorteil von \ac{ConvL}, der darin besteht, die Speicheranforderung deutlich zu reduzieren, indem es die Gewichte verteilt.
	
	\begin{figure*}[h]
		\centering
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics{stride1}
			\caption{\emph{Schrittgröße=(1,1) } }
			\label{fig:stride1}
		\end{subfigure}%
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics{stride2}
			\caption{ \emph{Schrittgröße=(2,2) } }
			\label{fig:stride2}
		\end{subfigure}
	\end{figure*}
	\item  \textbf{Schrittgröße}(\emph{Stride})\\
	
	Da ein Filter nur einen kleinen Bereich des Bilds wahrnehmen kann,wird eine Schrittgröße verwendet, um die Bewegung des Filters auf dem Bild zu steuern.Das Filter wird über das Bild von links nach rechts, von oben nach unten bewegt. Sei $ S:=(n,m) $  die Schrittgröße, dann wird das Filter von $ n $ Pixeln nach rechts für jede horizontale Bewegung des Filters und $ m $ Pixeln nach unten für jede vertikale Bewegung des Filters bewegt(siehe Abbildung \ref{fig:stride1} und \ref{fig:stride2}).Wie die folgende Tabelle zeigt,hängt die räumliche Dimension des Outputs sehr von der Schrittgröße ab.
	
	\begin{table}[h]
		\centering
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			\textbf{Imagegröße} & \textbf{\emph{Stride}} & \textbf{\emph{Filtergröße}} & \textbf{\textit{Output (räumliche Dim.)}}&\textbf{\emph{Mit Padding}}\\ \hline
			$ (100, 100, 3) $ &{$ (1,1) $ }& $ (1,1) $ &{$ (100,100) $ }&$ (100,100) $ \\ \hline
			$ (100, 100, 3) $ &\textcolor{red}{$ (1,1) $ }& $ (3,3) $ &\textcolor{red}{$ (98,98) $ }&$ (100,100) $ \\ \hline
			$ (100, 100, 3) $ &\textcolor{red}{$ (2, 2) $ } & $ (3,3) $ &\textcolor{red}{$ (49,49) $ }&$ (50,50) $ \\ \hline
			$ (100, 100, 3) $ &$ (1,1) $ & \textcolor{blue}{$ (4,4) $ }&\textcolor{blue}{$ (97, 97) $ } & $ (100, 100) $\\ \hline
			$ (100, 100, 3) $ &$ (1,1) $ & \textcolor{blue}{$ (10,10) $ }&\textcolor{blue}{$ (91, 91) $ } &$ (100, 100) $\\ \hline
		\end{tabular}
		\caption{Auswirkung von Schrittgröße,Filtergröße und Padding auf Output eines $ (100, 100, 3) $ Bild.}
		\label{tab:Stride and filter size}
	\end{table}
	
	\item \textbf{\textit{Padding}}\\
	Mit einem großen Filter lernt man in der Regel "mehr"{} als mit einem kleinen.Aber wie in Tabelle \ref{tab:Stride and filter size} zu sehen, habe man eine Reduktion der Dimension, wenn ein Filter mit Filtergröße $ >1 $ angewendet wird und um die Dimension zu behalten, wird vor der Anwendung der Filter auf das Bild eine Füllung(\textit{padding}) an den Rändern des Bilds gemacht. Diese Füllung ermöglicht erstens den Entwurf immer tiefer Netzwerke, denn es gibt nach jedem \ac{ConvL} einen kleinen Dimensionverlust und zweitens,dass die Information an Rändern nicht zu schnell verschwunden werden.
	
\end{itemize}
In einem \ac{CNN} mit mehreren \acsp{ConvL} kümmern sich die ersten \acsp{ConvL} um das Erlernen von einfachen Merkmale wie Winkel, Kanten oder Linien und je tiefer das \ac{CNN} ist, desto komplexer sind die extrahierten Merkmale, also die früher entdeckten Features werden kombiniert, um komplexe Features wie .Eine Vorverarbeitung der Netzeingangsdaten zur Extraktion der relevanten Information nicht mehr nötig. 
\begin{figure}[h]
	\centering
	\begin{subfigure}{\textwidth}
		\centering
		\caption{Matrixdarstellung}
		\newbox\dumbox
		\newcommand{\mymark}[2]{%
			\setbox\dumbox=\hbox{#2}%
			\hbox to \wd\dumbox{\hss%
				\tikz[overlay,remember picture,baseline=(#1.base)]{ \node (#1) {\box\dumbox}; }%
				\hss}%
		}
		\newcommand*{\putunder}[2]{%
			{\mathop{#1}_{\textstyle #2}}%
		}
		
		
		\[ \putunder{\begin{array}{|*{9}{c}|}
			\hline
			\mymark{t}{0}& 0& 3&  3& 3& 0&  \mymark{s}{0}& 0& 0\\ 
			0& \mymark{f}{2}& 0&  3& 2& 0&  0& 2& 0\\ 
			2& 0& \mymark{t1}{2}&  2& 0& 2&  2& 0& \mymark{s1}{2}\\ 						
			\mymark{q}{1}& 1& 1&  \mymark{r}{1}& 1& 1&  1& 1& 1\\ 			
			1& 0& 1&  0& 2& 0&  1& 0& 1\\ 
			0& 0& \mymark{q1}{1}&  2& 0& \mymark{r1}{2}&  0& 0& 1\\ 						
			\mymark{b}{1}& 1& 1&  1& 1& 1&  \mymark{j}{1}& 3& 1\\ 
			3& 0& 3&  1& 2& 0&  3& \mymark{f1}{0}& 3\\ 
			0& 3& \mymark{b1}{0}&  2& 0& 2&  0& 0& \mymark{j1}{0}\\  \hline
			\end{array} }{\text{(9,9)Bild}}  
		\quad \quad \times  \quad \quad
		\putunder{\begin{array}{*{3}{|c}|}
			\hline
			0&0&0 \\ \hline
			0&1&0 \\ \hline
			1&0&1\\ \hline
			\end{array}}{Filter}  
		\quad \quad = \quad \quad
		\putunder{ \begin{array}{ *{3}{|c}|}
			\hline
			\mymark{v}{6}&6&\mymark{ss}{6} \\ \hline
			\mymark{qq}{1}&\mymark{rr}{6}&1 \\ \hline
			\mymark{bb}{0}&0&\mymark{jj}{0}\\ \hline
			\end{array}  }{\text{(3,3)Feature-Map}} \]
		
		\begin{tikzpicture}[overlay, remember picture]
		\draw[green, fill=green, opacity=.2]   (t.north west) rectangle (t1.south east);
		\draw[red, fill=red, opacity=.2]   (r.north west) rectangle (r1.south east);
		\draw[yellow, fill=yellow, opacity=.3]   (j.north west) rectangle (j1.south east);
		\draw[red]   (f.north west) rectangle (f1.south east);
		\draw[blue, fill=blue, opacity=.5] (b.north west) rectangle (b1.south east) ;
		\draw[Sepia, fill=Sepia, opacity=.2]   (s.north west) rectangle (s1.south east);
		
		\draw[green, fill=green, opacity=.2]   (v.north west) rectangle (v.south east);
		\draw[red, fill=red, opacity=.2]   (rr.north west) rectangle (rr.south east);
		\draw[yellow, fill=yellow, opacity=.2]   (jj.north west) rectangle (jj.south east);
		\draw[blue, fill=blue, opacity=.2]   (bb.north west) rectangle (bb.south east);
		%	\draw[yellow, fill=yellow, opacity=.2]   (qq.north west) rectangle (qq.south east);
		\draw[Sepia, fill=Sepia, opacity=.2]   (ss.north west) rectangle (ss.south east);
		\end{tikzpicture}
		\label{fig:Faltungsoperation1}
	\end{subfigure}
	\begin{subfigure}{\textwidth}
		\centering
		\caption{ Pixeldarstellung }
		\includegraphics[width=\textwidth]{activation}
	\end{subfigure}
	
	\caption{Faltungsoperation mit einem $ 3\times 3$-Filter und Schrittgröße $ =3 $}
	\label{fig:Faltungsoperation}
\end{figure}

\subsubsection{Aktivierungsfunktion}
Das neuronale Netzwerk wird während dem Training mit sehr vielen Daten gespeist und das sollte in der Lage sein, aus diesen Daten zwischen relevanten und irrelevanten Informationen Unterschied zu machen.
Die Aktivierungsfunktion auch Transferfunktion oder Aktivitätsfunktion genannt, hilf dem \ac{NN} bei der Durchführung dieser Trennung. Es gibt sehr viele Aktivierungsfunktionen und in folgenden werden wir sehen, dass eine Aktivierungsfunktion je nach zu lösende Aufgaben  vorzuziehen ist.\[\begin{cases}
Y = f(\Sigma (Gewicht*Input + Bias))\\ f:= Aktivierungsfunktion
\end{cases} \]


\textbf{Binäre Treppenfunktion } ist extrem einfach, siehe Abbildung \ref{fig:Treppenfunktion}, definiert als
$  f(x)= 
\begin{cases}
1,& \text{if } x  \geq  a \text{  (a:= Schwellenwert )}\\
0,              & sonst
\end{cases} $. Sie ist für binäre Probleme geeignet, also Probleme wo man mit \textit{ja} oder \textit{nein} antworten sollte.Sie kann leider nicht mehr angewendet werden, wenn es mehr als zwei Klassen klassifiziert werden soll oder wenn das Optimierungsverfahren gradientenbasierend ist, denn Gradient immer null.
\begin{figure}[h]
	\caption{Binäre Treppenfunktion}
	\begin{subfigure}{.5\textwidth}
		\centering
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=-0.125,ymax=1.25,xmin=-10,xmax=10]
		\addplot[ultra thick,blue,samples at={0,10}] {1};
		\addplot[ultra thick,blue,samples at={0,-10.1}] {0};
		\end{axis}
		\end{tikzpicture}
		\caption{Binäre Treppenfunktion}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=-0.125,ymax=1.25,xmin=-10,xmax=10]
		\addplot[ultra thick,blue,samples at={-10.5,10.1}] {0};
		\end{axis}
		\end{tikzpicture}		
		\caption{Ableitung Binäre Treppenfunktion}
	\end{subfigure}
	\label{fig:Treppenfunktion}
	
\end{figure}

\textbf{Lineare Funktion } ist definiert als $ f(x) = ax, $	$ f '(x) = a$, siehe Abbildung \ref{fig:Lineare Funktion}. Sie ist monoton, null zentriert und differenzierbar. Es ist jetzt möglich,nicht mehr nur binäre Probleme zu lösen und mit gradientenbasierenden Optimierungsverfahren während der Backpropagation Parameter anzupassen, denn Gradient nicht mehr null, also sie ist besser als binäre Funktion .Nutzt ein mehrschichtiges Netz die lineare Aktivierungsfunktion, so kann es auf ein einschichtiges Netz überführt werden und mit einem einschichtigen Netz können komplexe Probleme nicht gelöst werden.Außerdem ist der Gradient konstant. Der Netzfehler wird also nach einigen Epochen nicht mehr minimiert und das Netz wird immer das Gleiche vorhersagen.		
\begin{figure}[h]
	\caption{Lineare Funktion}
	\begin{subfigure}{.5\textwidth}
		\centering
		
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=-5,ymax=5,xmin=-5,xmax=5]
		\addplot[ultra thick,blue] {x};
		\end{axis}
		\end{tikzpicture}
		\caption{Lineare Funktion: $ f(x) = x $}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=0.5,ymax=1.5,xmin=-5,xmax=5]
		\addplot[ultra thick,blue,samples at={-5.5,5.1}] {1};
		\end{axis}
		\end{tikzpicture}		
		\caption{Ableitung Lineare Funktion: $ f'(x) =1 $}
	\end{subfigure}
	\label{fig:Lineare Funktion}
	
\end{figure}

\textbf{Logistische Funktion} ist definiert als $f(x)=\frac{1}{1+exp(-x)} $ ,$ f'(x)= \frac{exp(x)}{(1+exp(x))^2}$, siehe Abbildung \ref{fig:sigmoid}. Sie ist differenzierbar, monoton, nicht linear und nicht null zentriert(hier nur positive Werte).Zwischen $ [-3,+3] $ ist der Gradient sehr hoch.Kleine Änderung in der Netzinput führt also zu einer großen Änderung der Netzausgabe. Diese Eigenschaft ist bei Klassifikationsproblemen sehr erwünscht.Die Ableitung ist glatt und von Netzinput abhängig. Parameter werden während der Backpropagation je nach Netzinput angepasst.
Außerhalb von $ [-3,3]  $ ist der Gradient fast gleich null, daher ist dort eine Verbesserung der Netzleistung fast nicht mehr möglich.Dieses Problem wird Verschwinden des Gradienten \textit{(vanishing gradient problem)} genannt.Außerdem konvergiert das Optimierungsverfahre sehr langsam und ist wegen wegen der exponentiellen  ($ e^x $) Berechnung rechenintensiv.
\begin{figure}[h]
	\caption{Logistische Aktivierungsfunktion:$ sigmoid(x) $.}
	\centering
	\begin{subfigure}{.5\textwidth}	
		\centering	
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=0,ymax=1.25,xmin=-5,xmax=5]
		\addplot[blue,ultra thick] {1/(1+exp(-x))};
		\end{axis}
		\end{tikzpicture}		
		\caption{Logistische Aktivierungsfunktion.}
		
	\end{subfigure}%	
	\begin{subfigure}{.5\textwidth}	
		\centering	
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=-0.0,ymax=.3,xmin=-5,xmax=5]
		\addplot[blue,ultra thick] {exp(x)/((1+exp(x))^2)};
		\end{axis}
		\end{tikzpicture}		
		\caption{Ableitung der Logistische Funktion.}
	\end{subfigure}
	\label{fig:sigmoid}
	
\end{figure}

\textbf{Tangens Hyperbolicus} ist definiert als	$ tanh := 2sigmoid(x) -1$, siehe Abbildung \ref{fig:tanh}.Außer dass sie null zentriert ist, hat sie die gleichen Vor- und Nachteile wie die Sigmoid Funktion.\textcolor{red}{Sättigung fehl noch}
\begin{figure}[h]
	\caption{Tangens Hyperbolicus.}
	\begin{subfigure}{.5\textwidth}	
		\centering	
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=-1.25,ymax=1.25,xmin=-5,xmax=5]
		\addplot[blue,ultra thick] {tanh(x)};
		\end{axis}
		\end{tikzpicture}		
		\caption{Tangens Hyperbolicus.}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}		
		\centering
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=-0.125,ymax=1.25,xmin=-5,xmax=5]
		\addplot[blue,ultra thick] {2/(cosh(2*x)+1)};
		\end{axis}
		\end{tikzpicture}		
		\caption{Ableitung der Tangens Hyperbolicus.}
	\end{subfigure}
	\label{fig:tanh}		
\end{figure}

\textbf{Rectified Linear Unit}(ReLU) ist definiert als $f(x)= max(x,0) $, siehe Abbildung \ref{fig:relu}. Sie ist sehr leicht zu berechnen. Es gibt keine Sättigung wie bei \textit{Sigmoid} und \textit{tanh}. Sie ist nicht linear,deshalb kann den Fehler schneller propagiert werden.Ein größter Vorteil der ReLU-Funktion ist, dass nicht alle Neurone gleichzeitig aktiviert sind, negative Eingangwerte werden zu null,daher hat die Ausgabe von Neuronen mit negativen Eingangwerten keine Einfluss auf die Schichtausgabe, diese Neurone sind einfach nicht aktiv.Das Netz wird also spärlich und effizienter und wir haben eine Verbesserung der Rechenleistung.
Es gibt keine Parameteranpassungen, wenn die Eingangwerte negative sind, denn der Gradient ist dort null.Je nachdem wie die Bias initialisiert sind, werden mehrere Neuron töten,also nie aktiviert und ReLU ist leider nicht null zentriert. \textcolor{red}{ReLUs haben die wünschenswerte Eigenschaft, dass sie keine Eingangsnormalisierung benötigen, um eine Sättigung zu verhindern.}
\begin{figure}[h]
	\caption{ReLU Aktivierungsfunktion}
	\begin{subfigure}{.5\textwidth}
		\centering
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=-0.0,ymax=5,xmin=-5,xmax=5]
		\addplot[blue,ultra thick] {max(x,0)};
		\end{axis}
		\end{tikzpicture}
		\caption{ReLU Aktivierungsfunktion}
		
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=-0.25,ymax=1.25,xmin=-5,xmax=5]
		\addplot[ultra thick,blue,samples at={-5.5,0}] {0};
		\addplot[ultra thick,blue,samples at={0,5.1}] {1};
		\end{axis}
		\end{tikzpicture}		
		\caption{Ableitung der ReLU Funktion}
		
	\end{subfigure}
	\label{fig:relu}
\end{figure}

\textbf{Leaky ReLU Funktion} ist definiert als $  f(x)= 
\begin{cases}
x,& \text{if } x  >  0\\
0.01x,              & sonst
\end{cases} $, siehe Abbildung \ref{fig:LReLU}. Sie funktioniert genauso wie die ReLU-Funktion, außer dass sie das Problem des toten Neurons und sie ist null zentriert.Es gibt somit immer eine Verbesserung der Netzleistung, solange das Netz trainiert wird.Wenn das Problem von Leaky ReLU nicht gut gelöst wird, wird empfohlen, die \textit{Parametric ReLU }(PReLU) Aktivierungsfunktion zu verwenden, die während der Training selber lernt, Problem der toten Neurone zu lösen.
\begin{figure}[h]
	\caption{Leaky ReLU Funktion}
	\begin{subfigure}{.5\textwidth}
		\centering
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=-0.5,ymax=5,xmin=-5,xmax=5]
		\addplot[blue,ultra thick] {max(0.1 * x, x)};
		\end{axis}
		\end{tikzpicture}
		\caption{Leaky ReLU Funktion}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\begin{tikzpicture}
		\begin{axis}[width=5.5cm,height=4cm,ymin=-0.25,ymax=1.25,xmin=-5,xmax=5]
		\addplot[ultra thick,blue,samples at={-5.5,0}] {0};
		\addplot[ultra thick,blue,samples at={0,5.1}] {1};
		\end{axis}
		\end{tikzpicture}		
		\caption{Ableitung der Leaky ReLU Funktion}
	\end{subfigure}
	
	\label{fig:LReLU}
	
\end{figure}




\textbf{Softmax} ist definiert als $ f(x_1, x_2, \cdots, x_n) = \frac{(e^{x_1}, ê^{x_2}, \cdots, e^{x_n})}{\sum_{i =1}^{n}{e^{x_i}}} $.Die Softmax-Funktion würde die Ausgänge für jede Klasse zwischen null und eins zusammendrücken und auch durch die Summe der Ausgänge teilen. Dies gibt im Wesentlichen die Wahrscheinlichkeit an, dass sich der Input in einer bestimmten Klasse befindet. 

In allgemein wird die ReLU aufgrund des Problems der toten Neurone nur in versteckte Schichten und die Softmax-Funktion bei Klassifikationsproblemen und Sigmoid-Funktion bei Regressionsproblemen in Ausgabeschicht verwenden.

\subsubsection{Pooling Layer}\label{Pooling Layer}
Die Funktionsweise von Pooling-Schichten ist sehr ähnlich zu der von \acsp{ConvL}. Das Filter wird über die Inputdaten bewegen und dabei anstatt die Faltungsoperation durchzuführen, werden die Inputdaten Blockweise zusammengefasst. Ein Pooling-Layer besitzt nur ein Filter, das nicht wie in \acsp{ConvL} lernbar ist, sondern gibt nur an, wie groß der Block, der zusammengefasst wird, sein muss.
Als Standard werden ein $ 2 \times 2 $ Filter und eine $ 2 \times 2 $ Schrittgröße verwendet, was die Dimension der Inputdaten um die Hälfte reduziert. Interessanter dabei ist ,dass die wichtigen Informationen oder Muster nach der Pooling-Layer vorhanden bleiben und damit haben wir nicht nur eine Erhöhung der Rechengeschwindigkeit, sondern auch eine wesentliche Reduzierung der Netzparameter, was die Wahrscheinlichkeit einer Modelüberanpassung(\textit{Overfitting}) reduziert. Pooling-Schichten sind etwa invariant gegenüber kleiner Veränderung wie Parallelverschiebung\cite{4}.

\begin{figure}[h]
	\centering
	\begin{tabular}{cc}
			
			\begin{tabular}{c}	
				
				
				\begin{tikzpicture}
				
				\tikzset{square matrix/.style={
						matrix of nodes,
						column sep=-\pgflinewidth, row sep=-\pgflinewidth,
						nodes={draw,
							minimum height=#1,
							anchor=center,
							text width=#1,
							align=center,
							inner sep=0pt
						},
					},
					square matrix/.default=.5cm
				}
				\matrix[square matrix]
				{
					|[fill=green]|	16& |[fill=green]|	3 & |[fill=yellow]|2 &|[fill=yellow]| 13 \\
					|[fill=green]|	5 & |[fill=green]|	10 &|[fill=yellow]| 11 &|[fill=yellow]| 8 \\
					|[fill=red]|	9 & |[fill=red]|	6 & 7 & 12 \\
					|[fill=red]|	4 & |[fill=red]|	15 & 14 & 1 \\
				};
				
				\end{tikzpicture}\Arrow%
				
				
				\begin{tikzpicture}
				\centering
				
				\tikzset{square matrix/.style={
						matrix of nodes,
						column sep=-\pgflinewidth, row sep=-\pgflinewidth,
						nodes={draw,
							minimum height=#1,
							anchor=center,
							text width=#1,
							align=center,
							inner sep=0pt
						},
					},
					square matrix/.default=1cm
				}
				\matrix[square matrix]
				{
					|[fill=green]|	16 & |[fill=yellow]| 13 \\
					|[fill=red]|	15 & 14 \\
				};
				
				\end{tikzpicture}
			\end{tabular}

	&
			\begin{tabular}{c}
				
				\begin{tikzpicture}
				
				\tikzset{square matrix/.style={
						matrix of nodes,
						column sep=-\pgflinewidth, row sep=-\pgflinewidth,
						nodes={draw,
							minimum height=#1,
							anchor=center,
							text width=#1,
							align=center,
							inner sep=0pt
						},
					},
					square matrix/.default=.5cm
				}
				
				\matrix[square matrix]
				{
					|[fill=green]|	16& |[fill=green]|	3 & |[fill=yellow]|2 &|[fill=yellow]| 13 \\
					|[fill=green]|	5 & |[fill=green]|	10 &|[fill=yellow]| 11 &|[fill=yellow]| 8 \\
					|[fill=red]|	9 & |[fill=red]|	6 & 7 & 12 \\
					|[fill=red]|	4 & |[fill=red]|	15 & 14 & 1 \\
				};
				
				\end{tikzpicture}\Arrow
				
				\begin{tikzpicture}
				
				\tikzset{square matrix/.style={
						matrix of nodes,
						column sep=-\pgflinewidth, row sep=-\pgflinewidth,
						nodes={draw,
							minimum height=#1,
							anchor=center,
							text width=#1,
							align=center,
							inner sep=0pt
						},
					},
					square matrix/.default=1cm
				}
				
				\matrix[square matrix]
				{
					|[fill=green]|	8.5 & |[fill=yellow]| 8.5 \\
					|[fill=red]|	8.5 & 8.5 \\
				};
				
				\end{tikzpicture}
			\end{tabular}

		
	\end{tabular}
			\caption{Funktionsweise der Pooling-Sicht mit Pooling\_size$ =(2,2) $ und $ Stride =2$}
			\label{fig:Pooling}
\end{figure}




Je nachdem wie die Blöcke in \ac{PooL} zusammengefasst werden, haben die \acsp{PooL} unterschiedliche Namen. Werden die Werte eines Blockes durch den Maximalwert des Blocks, dann sprechen wir von Max-Pooling-Layer (siehe Abbildung \ref{fig:Pooling} links), wenn sie durch den Mittelwert  des Blocks ersetzt, wird von Average-Pooling-Layer (siehe Abbildung \ref{fig:Pooling} rechts ) und wenn die Filtergröße gleich die räumliche Dimension der Eingangdaten ist, sprechen wir von Global-Max-Pooling-Layer und Global-Average-Pooling-Layer, es wird also alle Neurone in einem Kanal zu einem Neuron, die Ausgabedimension solche Schicht entspricht der Anzahl der Kanäle bzw. Tiefe der Inputdaten.

Das Global-Pooling-Layer wird sehr oft angewendet, um das Vorhandensein von Merkmale in Daten aggressiv zusammenzufassen. Es wird auch manchmal in Modellen als Alternative zur Flatten-Schicht, die mehrdimensionale Daten zu eindimensionale umwandelt, beim Übergang von \acsp{ConvL} zu einem \ac{FCL}  verwendet.



\subsubsection{Multi-layer Perzeptron (Fully Connected Layer)}\label{FC}
Nachdem die relevanten lokalen Merkmale durch die Wiederholung von Conv und Pooling-Schichten extrahiert werden sind, wenden sie in einem \ac{FCL} kombiniert, um das Ergebnis jeder Klasse zu berechnen. Die \acsp{FCL} des \ac{CNN} ermöglichen, Informationssignale zwischen jeder Eingangsdimension und jeder Ausgangsklasse zu mischen, so dass die Entscheidung auf dem gesamten Bild basieren kann und ihm eine Klasse zugewiesen werden kann. Die \acsp{FCL} funktionieren eigentlich genau wie \acsp{ConvL}, außer dass jedes Neuron in \ac{FCL} mit allen Neuronen und nicht mit einem kleinen Bereich von Neuronen im vorherigen Layer verbunden ist.Ein \ac{NN} mit nur \acsp{FCL} sieht wie in Abbildung\ref{KNN} aus.

\def\layersep{2.5cm}
\begin{figure}[h]
	\centering
	\begin{tikzpicture}[shorten >=1pt,->,draw=black!50, node distance=\layersep]
	\tikzstyle{every pin edge}=[<-,shorten <=1pt]
	\tikzstyle{neuron}=[circle,fill=black!25,minimum size=17pt,inner sep=0pt]
	\tikzstyle{input neuron}=[neuron, fill=green];
	\tikzstyle{output neuron}=[neuron, fill=yellow];
	\tikzstyle{hidden neuron}=[neuron, fill=red];
	\tikzstyle{annot} = [text width=4em, text centered]
	
	% Draw the input layer nodes
	\foreach \name / \y in {1,...,4}
	% This is the same as writing \foreach \name / \y in {1/1,2/2,3/3,4/4}
	\node[input neuron, pin=left:Eingabe \y] (I-\name) at (0,-\y) {};
	
	% Draw the hidden layer nodes
	\foreach \name / \y in {1,...,5}
	\path[yshift=0.5cm]
	node[hidden neuron] (H-\name) at (\layersep,-\y cm) {};
	
	% Draw the output layer node
	\node[output neuron,pin={[pin edge={->}]right:Ausgabe 1}, right of=H-2, yshift=-0.5cm] (0) {};
	\node[output neuron,pin={[pin edge={->}]right:Ausgabe 2}, right of=H-3, yshift=-0.5cm] (1) {};
	
	% Connect every node in the input layer with every node in the
	% hidden layer.
	\foreach \source in {1,...,4}
	\foreach \dest in {1,...,5}
	\path (I-\source) edge (H-\dest);
	
	% Connect every node in the hidden layer with the output layer
	\foreach \x in {0,1}
	\foreach \source in {1,...,5}
	\path (H-\source) edge (\x);
	
	
	% Annotate the layers
	\node[annot,above of=H-1, node distance=1cm] (hl) {Versteckte Schicht};
	\node[annot,left of=hl] {Eingabe- schicht};
	\node[annot,right of=hl] {Ausgabe schicht};
	\end{tikzpicture}
	
	\caption{Darstellung eines  neuronalen Netzes }
	\label{KNN}
\end{figure}


Aufgrund der hohen Anzahl von Verbindungen zwischen Neuronen in einem \ac{FCL} wird viel Speicher und Rechenleistung benötigt und verlangsamt auch das Training, es ist auch einer der Gründe, weshalb die \acsp{FCL} meist nur in der letzten Schicht von \ac{CNN} zur Klassifizierung verwendet werden und die Anzahl der Neuronen in letzter Schicht entspricht der Anzahl von Klassen.









\subsection{Backforward }

\subsubsection{Fehlerfunktion}\label{Fehlerfunktion}

Das Training von \acsp{CNN} besteht darin, den vom \ac{CNN} begangenen Fehler zu korrigieren bzw. zu minimieren, daher wird es sehr oft als ein Optimierungsverfahren betrachtet.
Wie gut die Vorhersage des neuronalen Netzes gerade ist, wird durch eine Fehlerfunktion auch Kostenfunktion genannt quantifiziert oder angegeben.
Die Fehlerfunktion bringt die Ausgabewerte des \acsp{NN} mit den gewünschten Werten in Zusammenhang. Sie ist ein nicht-negativer Wert und je kleiner dieser Wert wird, desto besser ist die Übereinstimmung des \acsp{CNN}.Es wird in Laufe des Trainings von \acsp{CNN} versucht, diese Kostenfunktion mit Gradient basierten Verfahren zu minimieren(siehe Absatz \ref{Gradientenabstieg})


Die meisten benutzten Kostenfunktionen sind die Kreuzentropie (\textit{cross-entropy}, Gleichung \ref{CE})(CE) und die mittlere quadratische Fehler (\textit{mean squared error},Gleichung \ref{MSE})(MSE). 

\begin{align}
\label{MSE}	
MSE(Y, \widehat{Y}) =&\frac{1}{n}\sum_{i = 1}^{n}(Y_i - \widehat{Y}_i)^2\\
\label{CE}
CE(Y, \widehat{Y}) =&-\frac{1}{n}\sum_{i = 1}^{n}(Y_i\log(\widehat{Y}_i) +(1-Y_i)\log(1- \widehat{Y}_i))
\end{align}

\begin{align*}
Y:=\{Y_1,\cdots, Y_n\} :&\text{Die tatsächlichen Werte} \\
\widehat{Y}:=\{\widehat{Y}_1,\cdots, \widehat{Y}_n\} :&\text{Die Ausgabeweerte des neuronalen Netzes}
\end{align*}
Im Gegenteil zu CE Fehlerfunktionen,die sich nur auf Wahrscheinlichkeitsverteilungen anwenden lassen, können die MSE auf beliebige Werte angewendet werden. Nach \cite[Pavel et al]{7} ermöglicht die CE-Verlustfunktion ein besseres Finden lokaler Optima als die MSE-Verlustfunktion und das soll daran liegen, dass das Training des MSE Systems schneller in einem schlechten lokalen Optimum stecken bleibt, in dem der Gradient fast null ist und damit keine weitere Reduzierung der Netzfehler ermöglicht.Im Allgemein ist die CE Kostenfunktion für die Klassifikationsprobleme und die MSE Fehlerfunktion für die lineare Regression-Probleme besser.

\subsubsection{ Gradient}\label{Gradient}
Der Gradient einer Funktion ist die erste Ableitung einer Funktion und in mehrdimensionalem Raum ist der Gradient einer Funktion der Vektor, dessen Einträge  die ersten partiellen Ableitungen der Funktion sind. Der Gradient an einem Punkt gibt die Richtung der steilsten Anstieg der Funktion an diesem Punkt.  Also da wir die Kostenfunktion minimieren möchten, sollen wir lieber immer in die Gegenrichtung des Gradienten gehen.In auf dem Gradient basierten Optimierungsverfahren wird der Gradient benutzt, um die lokalen oder globalen Extremwerte(hier das Minimum) zu erreichen.
Da wir jetzt die Richtung des Minimums herausgefunden haben, bleibt noch zu bestimmen ,wie wir in diese Richtung gehen  sollen.

\subsubsection{Lernrate}\label{Lernrate}
Die Lernrate oder Schrittweite beim maschinellen Lernen ist ein Hyperparameter, der bestimmt, inwieweit neue gewonnene Informationen alte Informationen überschreiben sollen\cite{LearningRate}, in anderen Worten wie schnell wir ans Ziel Kommen.
Je nachdem wie die Lernrate gesetzt wird, werden bestimmte Verhalten beobachtet (Siehe Absatz \ref{Experiment:Lernrate}) und sie nimmt sehr oft Werte zwischen $ 0.0001 $ und $ 0.5 $:
Die Lernrate muss allerdings im Intervall  $]0,1[$ Werte annehmen, sonst ist das Verhalten des \ac{NN} nicht vorhersehbar bzw. konvergiert das Verfahren einfach nicht.
Für jeden Punkt $ x $ aus dem Parameterraum gibt es eine optimale Lernrate $ \eta_{opt}(x) $, sodass das globale oder lokale Minimum sofort nach der Parameteranpassung erreicht wird. Da $ \eta_{opt}(x) $ am Trainingsanfang leider nicht bekannt ist, wird die Lernrate in die Praxis vom Programmierer basiert auf seine Kenntnisse mit \acsp{NN} oder einfach zufällig gesetzt.

\subsubsection{Gradientenabstiegsverfahren}\label{Gradientenabstiegsverfahren}
Aktuelle leistungsfähige \ac{DNN} bestehen fast immer aus Million Variable (lernbarer Parameter). Wir können uns ein \ac{DNN} als eine Gleichung mit Millionen von Variablen(lernbare Parameter) vorstellen, die wir lösen möchten. Mit Hilfe der Daten wollen wir uns in einem Raum, dessen Dimension größer als eine Million ist, bewegen, um die optimalen Parameter(Parameter, die die Daten korrekt abbilden) zu finden. Aufgrund der unendlichen Anzahl von Punkten im solchen Räume wäre es nicht sinnvoll,einen Punkt zufällig auszuwählen, dann überprüfen, ob er optimal ist und, wenn nicht, nochmals einen anderen Punkt zufällig auszuwählen. Genauer zu diesem Zeitpunkt kommen Gradientenabstiegsverfahren zum Einsatz.
Die Gradientenabstiegsverfahren sind Verfahren, die auf dem Gradient basieren, um Optimierungsprobleme zu lösen.Hier wird Gradientenabstiegsverfahren verwendet, die optimalen Parametern zu finden oder anzunähern.

\begin{center}
	\textbf{Ablauf eines Gradientenverfahrens im \ac{DNN} }
\end{center}
Das Gradientenabstiegsverfahren kann in drei Hauptschritte aufgeteilt werden.Die Abbildung \ref{fig:Backprop} stellt das Backpropagation-Verfahren bildlich dar.
Beim ersten Schritt  wird ein zufälliger Punkt aus dem Parameterraum ausgewählt und davon ausgehend wird der Parameterraum exploriert. Das entspricht der Netzparameterinitialisierung am Trainingsanfang.
Der zweite Schritt besteht darin, die Abstiegsrichtung zu bestimmen.Dazu werden zuerst die Eingangdaten in das \ac{NN} eingespeist(\textit{Forwardpropogation}), danach wird der Fehler zwischen den Netzvorhersagen und den korrekten Werten berechnet und ein Fehler gibt es (fast) immer, denn die Initialisierung wird zufällig gemacht und die Wahrscheinlichkeit, dass wir von Anfang an die optimalen Werte finden, ist verschwindend klein und zuletzt wird der Gradient(\ref{Gradient}) der Kostenfunktion in abhängig von den gegebenen Eingangdaten und den erwarteten Werten berechnet. 
Beim letzten Schritt wird die Schrittweite bestimmen.Die Lernrate (\ref{Lernrate}) oder die Schrittweite wird vor Trainingsbeginn festgelegt oder während des Trainings abhängig von aktuellem Netzzustand allmählich adaptiert.


\begin{figure}[h]
	\fcolorbox{blue}{white}{
		\centering
		\begin{tikzpicture}[->,>=stealth',shorten >=3pt,auto,node distance=3cm,semithick]
		\tikzstyle{every state}=[rectangle, rounded corners, draw=purple, fill=gray!50,text=black, ultra thick]
		\tikzstyle{every edge}=[draw=blue,text=blue, ultra thick]
		
		
		\node[state] 		 (1)                    {\parbox{3cm}{\centering Eingangdaten:\\$ x=x_1, \cdots,x_n $}};
		\node[state]         (2) [below, fill=yellow,xshift=3cm, yshift=-2cm] 		{\parbox{3cm}{\centering Neuronale Netze\\ (Forward-Pass)\\$ y =f(x,w,b)  $}};
		\node[state]         (3) [right,xshift=3cm] {\parbox{5cm}{\centering Netzparameter\\Gewichte:$w= w_1, \cdots, w_n $\\Bias:b}};
		\node[state]         (4) [below of=2] 		{\parbox{4cm}{\centering Netzvorhersagen:\\$y= y_1, \cdots,y_n $}};
		\node[state]         (5) [right of=2, xshift=3cm, fill=yellow] 		{ \parbox{4cm}{\centering Fehlerstimmung:\\$ kost(y,\widehat{y}) $}};
		\node[state]         (6) [right of=3, xshift=3cm]       {\parbox{4cm}{\centering Tatsächliche Werte:\\  $ \widehat{y}=\widehat{y}_1, \cdots,\widehat{y}_n $}};
		\node[state]		 (7) [below of=5, fill=yellow]		{\parbox{5cm}{\centering Netzparameter Anpassen\\$ w_i = w_i -\eta \frac{\delta kost(y, \widehat{y})}{\delta w_i} $\\$ b = b -\eta \frac{\delta kost(y, \widehat{y})}{\delta b} $}};
		
		\path (1)edge node{}(2);
		\path (3)edge node{}(2);
		\path (2)edge node{}(4);
		\path (4)edge node{}(5);
		\path (6)edge node{}(5);
		\path (5)edge node{}(7);
		\path (7)edge[bend left, draw=red] node[rotate=100, xshift=8ex, text=red]{Backward-Pass}(3);
		
		\end{tikzpicture}}
	\begin{center}
		\begin{tabular}{r@{: }l r@{: }l}
			$f(x,w,b)$ & Netzfunktion. & $kost(y,\widehat{y})$ & Kostenfunktion. \\ 
			$ \eta $& Lernrate &$ \frac{\delta kost(y, \widehat{y})}{\delta w_i} $ & Ableitung der Kostenfunktion abhängig von $ w_i $.
		\end{tabular}
	\end{center}
	
	\caption{Ablauf der Backpropagation}
	\label{fig:Backprop}
\end{figure}

Pfeile in Abbildung \ref{fig:Backprop} weisen nur den Prozessablauf hin.







\begin{center}
	\textbf{Variante des Gradientenverfahrens}
\end{center}
Bisher existiert drei Variante des Gradientenabstiegsverfahren, die sich nur durch die Größe der Daten, die sie verwendet, um den Gradienten der Kostenfunktion berechnet, unterscheidet.Zum Aktualisierung der Netzwerkparameter nutzen sie jeweils die Gleichung \eqref{GD}.

\begin{equation}\label{GD}
\theta_{t+1} = \theta_{t} -\eta g_{t}, \quad g_t=\frac{\delta E}{\delta \theta_{t}}
\end{equation}
\begin{center}
	\begin{tabular}{r@{: }l r@{: }l}
		$ \eta$& Lernrate & $ E$ & Die Fehlerfunktion\\
		$ \theta_{t} $& Netzwerkparameter zum Zeitpunkt $ t $
	\end{tabular}
\end{center}
\subparagraph{Stochastic Gradient Descent (SGD):}
Bei SGD wird jeweils ein Element bzw. Sample aus der Trainingsmenge durch das \ac{NN} durchlaufen und den jeweiligen Gradienten berechnen, um die Netzwerkparameter zu aktualisieren.Diese Methode wird sehr oft online Training  genannt,denn jedes Sample aktualisiert das Netzwerk. SGD verwendet geringer Speicherplatz und die Iterationen sind schnell durchführbar.Zusätzlich kann die Konvergenz für großen Datensatz wegen der ständigen Aktualisierung der Netzwerkparameter beschleunigen.Diese ständigen Aktualisierung hat die Schwankung der Schritte in Richtung der Minima zur Folge, was die Anzahl der Iteration bis zum Erreichen des Minimums deutlich ansteigt und dabei helfen kann, aus einem unerwünschten lokalen Minimum zu entkommen.Ein großer Nachteil dieses Verfahren ist der Verlust der parallelen Ausführung, es kann jeweils nur ein Sample ins \ac{NN} eingespeist werden.
\subparagraph{Batch Gradient Descent (BGD):}
BGD funktioniert genauso wie SGD, außer dass der ganze Datensatz statt jeweils ein Element aus dem Datensatz zur Netzwerkparameteraktualisierung genutzt wird.Jetzt kann das Verfahren einfach parallel ausgeführt werden, was den Verarbeitungsprozess des Datensatzes stark beschleunigt. BGD weist weniger Schwankungen in Richtung des Minimums der Kostenfunktion als SGD auf, was das Gradientenabstiegverfahren stabiler macht.Außerdem ist das BGD recheneffizienter als das SGD, denn nicht alle Ressourcen werden für die Verarbeitung eines Samples, sondern für den ganzen Datensatz verwendet.BGD ist leider sehr langsam,denn die Verarbeitung des ganzen Datensatz kann lange dauern und es ist nicht immer anwendbar, denn sehr große Datensätze lassen sich nicht im Speicher einspeichern.
\subparagraph{Mini-batch Stochastic Gradient Descent(MSGD): }
MSGD ist eine Mischung aus SGD und BGD.Dabei wird der Datensatz in kleine Mengen (\textit{Mini-Batch oder Batch}) möglicherweise gleicher Größe aufgeteilt.Je nachdem wie man die Batch-Große setzt, enthalten wir SGD oder BGD wieder. Das Training wird Batchweise durchgeführt, d.h. es wird jeweils ein Batch durch das \ac{NN} propagiert, der Verlust jedes Sample im Batch wird berechnet und dann deren Durchschnitt benutzt, um die Netzwerkparameter zu anzupassen.MSGD verwendet den Speicherplatz effizienter und kann von Parallelen Ausführung profitieren. Noch  dazu konvergiert MSGD schneller und ist stabiler. In die Praxis wird fast immer das MSGD Verfahren bevorzugt.

Zum besserer Anwendung der Gradientenabstiegsverfahren wurden mehrere Optimierte Lernverfahren entwickelt. Im folgenden wird ein kurzer Einblick über die bekanntesten Lernverfahren(\textit{Optimizer})  gegeben.\\
Alle heutige Optimizer haben SGD als Vorfahren und der Hauptnachteil von SGD ist , dass es die gleiche Lernrate für die Anpassung aller Netzwerkparameter verwendet und diese Lernrate wird auch während des Trainings nie geändert. 



% Literaturverzeichnis (beginnt auf einer ungeraden Seite)
% \newpage 
\section{Kompression von \ac{DNN}}
Die neueren maschinellen Lernmethoden verwenden immer tiefer neuronale Netze wie z.B \textit{Xception(134 Layers),MobileNetV2(157 Layers), InceptionResNetV2(782 Layers)}, um Ergebnisse auf dem neuesten Stand der Technik zu erzielen. Aber die Verwendung von sehr tiefer \acsp{NN} bringt mit sich nicht nur eine deutliche Verbesserung der Modellleistung, sondern auch einen bedeutenden Bedarf an Rechenleistung und an Speicherplatz, was der Einsatz solcher Modelle auf Echtzeitsystemen mit begrenzten Hardware-Ressourcen schwierig macht.Es wurden bisher mehrere Ansätze untersucht, um die dem \ac{NN} zugewiesenen Ressourcen effizienter zu nutzen:
\begin{itemize}
	\item Die Modellbeschneidung(\textit{Network pruning}), die die redundanten und  die nicht relevanten Verbindungen zwischen Neuronen entfernt.
	 \item Die Destillation von \acsp{NN}, die ermöglicht, die großen Modellen in kleinen  zu komprimieren. 	
 \item Die Quantisierung von \ac{NN}, die für die Darstellung von einzelnem Netzparameter weniger als $ 32 $ Bits nutzt.
 \item  Huffman-Codierung, die eine komprimierte Darstellung des Netzwerks ermöglicht.
\end{itemize} 
Im folgenden werden nur die Beschneidung, die Quantisierung von \ac{NN} und die Anwendung von Huffman auf \ac{NN} mehr eingegangen werden.
%\\
%
%Neuronale Netze sind sowohl rechenintensiv als auch speicherintensiv, was ihre Bereitstellung auf eingebetteten Systemen mit begrenzten Hardware-Ressourcen erschwert\cite{5}. 
%Um dem Problem von Rechenzeit und Speicherplatzbedarf entgegenzuwirken, wird die tiefe Kompression(\textit{Deep Compression}) Technik von \cite[Han et al]{5} eingeführt.
%Die Deep Compression Technik besteht aus drei Phasen:Netzwerkbereinigung (\textit{Pruning Network}),Quantizierung(\textit{Quantization}) und Huffman-Codierung(\textit{Huffman Coding})

\subsection{Pruning Network}
Wie oben schon erwähnt, wird beim \textit{Pruning} neuronaler Netze versucht, unwichtige oder redundante Verbindungen oder komplette Neuronen aus dem Netzwerk zu entfernen, um ein Netz mit möglichst geringer Komplexität zu erhalten. Mit unwichtigen Verbindungen werden die Parameter (Gewichte und Bias) gemeint, die fast null sind, denn Parameter mit Nullwert haben keinen Einfluss auf das Output des Neurons, sie sind einfach überflüssig. Während oder nach dem Training gibt es mehrere Parameter, die nicht wirklich zum Neuronenergebnis beitragen, obwohl sie keinen Nullwert haben, deshalb ist es zum Reduzieren der Netzwerkdichte notwendig, einen Schwellenwert $ \theta $ entweder zu setzen oder zu bestimmen und dann werden alle Parameter mit einem Wert in $ [-\theta, \theta] $  eliminiert.

Das Pruning-Verfahren bietet einige Vorteile wie Reduzierung der Speicher- und Hardwarekosten, die Trainingsbeschleunigung , die schnellere Antwortzeit und das Verringern der Wahrscheinlichkeit der Overfitting(\ref{Overfitting}).
Es ist sehr wichtig zu beachten, dass die Anwendung vom Pruning-Verfahren auf ein \ac{NN} nur Sinn macht, wenn das \ac{NN} schon trainiert ist, sonst macht das Pruning nur eine Reduktion der Anzahl der Netzwerkparameter.

Es gibt zwei Hauptszenarien für das Pruning von \ac{NN}.
Die erste besteht darin, die irrelevanten Verbindungen in einem komplett trainierten \ac{NN} zu entfernen. Mit komplett trainierten \ac{NN} wird gemeint, dass die erwünschte Genauigkeit schon erreicht ist. Im zweiten Szenario wird Pruning während des Trainings durchgeführt.Dabei wird vor Trainingsbeginn  bestimmte Dinge festgelegt,wie z.B. ab wann wird das Netzwerk beschnitten und wie oft es durchgeführt werden soll. 

Das erste Szenario ist einfacher anzuwenden, denn man muss nur darauf warten, bis es keine Verbesserung der Genauigkeit des \ac{NN} mehr gibt und dann Pruning auf das \ac{NN} anwenden, aber damit verliert man großen Vorteile des Pruning, die die Beschleunigung des Trainings und Reduzierung der Overfitting-Wahrscheinlichkeit sind.
Aus diesen Gründen wird in der Praxis das zweite Szenario bevorzugt, aber die richtigen Hyperparameter zu finden, ist kompliziert. Eine zu früh Beschneidung kann z.B. die Genauigkeit des \ac{NN} zu sehr verschlechtern, denn es kann sein, dass eine Verbindung, die nur nach einer späteren Gewichtsanpassung zum Ergebnis eines Neurons  hätte beigetragen können, entfernt würde, aber es bietet eine Beschleunigung des Trainings. Was eine zu spät Beschneidung angeht, haben wir fast die gleichen Nachteile wie im ersten Szenario und eine sehr häufiges Pruning kann das Training  auch verlangsamen.Das ganze Prozess musst leider mehrmals angewendet, um die richtigen Hyperparameter zu finden.


Das Pruning-Verfahren kann  während oder nach dem Training eines \ac{NN} angewendet
Das Pruning reduziert die Anzahl der Parameter, was die Netzkomplexität, die Rechenzeit und auch die Wahrscheinlichkeit des Overfitting reduziert.Für AlexNet und VGG-16 Modell wird durch Pruning die Anzahl der Parameter um 9 bzw. 13 mal reduziert\cite{5}.\textcolor{blue}{Zur effizienteren Speicherung des beschnitten Netzes kann ein CRS (\textit{Compressed Row Storage}) oder CCS (\textit{Compressed Column Storage}) Format verwendet werden, das $ 2a+n+1 $ statt $ n*n $ Zahlen speichert, wobei $ a $ die Anzahl der Elemente ungleich Null und $ n $ die Anzahl der Zeilen oder Spalten der Matrix ist}. \\

Das Pruning-Verfahren kann per Hand( also durch festlegen von Hyperparametern vor Trainingsbeginn)  oder automatisch(die Hyperparameter werden während des Trainings gelernt) durchgeführt werden. Erstmals von \cite[Han et al.]{5} vorgeschlagen, wird das Pruning-Verfahren per Hand durchgeführt und dabei wird vor dem Netztraining einen Schwellenwert(\textit{Threshold}) für alle Layers fixiert.Obwohl dieses Vorgehen gute Ergebnisse aufweist, hat es Nachteile, die nicht unberücksichtigt lassen werden können:Einerseits muss das Netz mehrmals erneut trainiert werden, nur um den Schwellenwert anzupassen und anderseits ist die Anzahl diese Iterationen eingeschränkt.In Abbildung \ref{fig:PN} ist der Ablauf des Pruning-Verfahrens dargestellt. Dieses Verfahren kann also zu einer nicht optimalen Konfiguration führen. Um dieser Probleme entgegenzuwirken, haben \cite[Manessi et al.]{Automated Pruning} das Pruning-Verfahren automatisiert.
\begin{figure}[h]
	\centering
	\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.5cm,semithick]
	\tikzstyle{every state}=[rectangle, rounded corners, draw=purple, fill=gray!50,text=black, ultra thick]
	\tikzstyle{every edge}=[draw=blue,text=blue, ultra thick]
	
	
	\node[state] 		 (1)                    {Neuronales Netz};
	\node[state]         (2) [below of=1, fill=yellow] 		{Neuronales Netz trainieren};
	\node[state]         (3) [below of=2] 		{Evaluierung der Wichtigkeit eines Neurons};
	\node[state]         (4) [below of=3] 		{die am wenigsten wichtigen Neuronen entfernen};
	\node[state]         (5) [below of=4] 		{Feinanpassung  (Fine-tuning)};
	\node[state]         (6) [below of=5, fill=yellow]       {Netz weiter Beschneiden?};
	\node[state]		 (7) [below of=6]		{Netzbescheiden stoppen};
	
	\path (1)edge node{}(2);
	\path (2)edge node{}(3);
	\path (3)edge node{}(4);
	\path (4)edge node{}(5);
	\path (5)edge node{}(6);
	\path (6)edge node{nein}(7);
	\path (6)edge[bend right] node[below right]{ja}(2);
	
	\end{tikzpicture}
	\caption{Ablauf der Netzbeschneidung (\textit{Pruning Network})}
	\label{fig:PN}
\end{figure}
Manessi et al.\cite{Automated Pruning} haben die Beschneidungsmethode verbessert, indem sie das Verfahren in Bezug auf die Schwellenparameter differenzierbar gemacht haben, in anderen Worten sind die Schwellenwerte wie Gewichte und Bias lernbare Netzparameter. Dadurch können während der Lernphase automatisch die besten Schwellenparameter zusammen mit den Netzwerkgewichten geschätzt werden, was die Trainingszeit stark verkürzt.Mit dieser Verbesserung kann mehr Verbindungen oder komplette Neuronen entfernt, denn statt eines globalen Schwellenwerts wird einen Schwellenwert für jede Schicht berechnet.\cite{Automated Pruning} \textcolor{red}{muss ich hier die Formeln eingeben?}

\subsection{ Quantisierung von \ac{NN}}
Die Quantisierung \cite{quantization1} bezieht sich auf den Prozess der Reduzierung der Anzahl der Bits,die für Darstellung einer Zahl notwendig sind. Im Bereich des \textit{Deep Learning} ist das Standard numerische Format für Forschung und Einsatz bisher 32-Bit Fließkommazahlen oder FP32, denn es bietet ein bessere Genauigkeit, aber die anderen Formaten wie 8-,4-,2- oder 1-Bits werden auch verwendet, obwohl sie mehr oder weniger ein Verlust an Genauigkeit aufweisen.

Die Verwendung von weniger genauen numerischen Formaten hat nicht nur einen kleinen Verlust der Netzleistung zur Folge, sondern auch die Verwendung von deutlich reduzierter Bandbreite und Speicherplatz. Noch dazu beschleunigt die Quantisierung die Berechnungen, denn die ganzzahlige Berechnung zum Beispiel ist schneller als die Fließkommaberechnung.

Die Quantisierung ist eigentlich nur die Abbildung eines großen Bereiches auf einen kleinen und dazu werden zwei Hauptwerte benötigt: der dynamische Bereich des Tensors und ein Skalierungsfaktor.
Angenommen haben wir einen dynamischen Bereich $ [0,500] $ und einen Skalierungsfaktor:$ 5 $, dann ergibt sich der neue Bereich $ [0, 100] $, es wird also Werte zwischen $ [5k, 5(k+1)] $ oder $ [5k -0.5, 5k +0.5] $ auf $ 5k $ abgebildet.Es ist sinnvoller,  die Skalierungsfaktors unter Berücksichtigung der Anzahl und der Verteilung der Werte in dynamischen Bereich des Tensors auszuwählen.

Im Allgemein wird  einen Skalierungsfaktor für jeden Tensor jeder Schicht berechnet und diese kann offline oder online gemacht werden.Bei der \textit{Offline} Berechnung werden vor der Bereitstellung des Modells einigen Statistiken gesammelt, entweder während des Trainings oder durch die Ausführung einiger Epochen auf dem trainierten FP32-Modell und basierend auf diesen Statistiken werden die verschiedenen Skalierungsfaktoren berechnet und nach der Bereitstellung des Modells festgelegt.Durch die Anwendung dieser Methode lauft man die Gefahr, dass zur Laufzeit die Werte, die außerhalb der zuvor beobachteten Bereiche auftreten, abgeschnitten werden, was zu einer Verschlechterung der Genauigkeit führen kann.Bei der \textit{online} werden die \textit{Min/Max}-Werte für jeden Tensor dynamisch zur Laufzeit berechnet. Bei dieser Methode kann es nicht zu einer Beschneidung kommen, jedoch können die zusätzlichen Rechenressourcen, die zur Berechnung der Min/Max-Werte zur Laufzeit benötigt werden, unerschwinglich.\cite{quantization1}\\

Es gibt zwei Arten und Weisen, wie die Quantisierung durchgeführt wird.Die erste ist das vollständige Training eines Modells mit einer gewünschten niedrigeren Bit-Genauigkeit(kleiner als 32 Bits).Die Quantisierung mit sehr geringer Genauigkeit ermöglicht ein potenziell schnelles Training und Inferenz, aber der Hauptproblem mit diesem Ansatz ist, dass Netzparameter nur bestimmte Werte annehmen können, so ist die Aktualisierung der Netzparameter bzw. das Backpropagation nicht mehr wohldefiniert.
Das zweite Szenario  quantisiert ein trainiertes FP32-Netzwerks mit einer geringeren Bit-Genauigkeit ohne vollständiges Training.Eine aggressive Quantisierung hat im Allgemein einen negativen Einfluss auf die Netzleistung und um diesen Leistungsabfall zu überwinden, wird sehr oft auf Methoden wie das erneuerte Training des Netz nach der Quantisierung, die gleichzeitige Verwendung von verschiedenen Formaten oder die uneinheitliche Quantisierung zurückgegriffen.

Vor kurzem haben \cite[Yoni et al]{quantizationYoni} einen neue Ansatz für die Quantisierung vorgeschlagen,der das lineare Quantisierungsproblem als \textit{Minimum Mean Squared Error} (MMSE) Problem löst und der nicht nur die 4-Bit(INT4) Quantisierung von schon trainierten Modellen ohne ein neues Training des Modells, sondern auch die Einsparung von Chipfläche (\textit{chip area}) ermöglicht. Obwohl diese Methode  minimalen Verlust der Genauigkeit(\textit{accuracy}) aufweist, liefert sie Ergebnisse auf dem neuesten Stand der Technik und nach \cite{quantizationYoni} weist dieser Ansatz den geringeren Genauigkeitsverlust als alle Quantisierungsverfahren auf.

\subsection{Huffman Codierung}
Die Huffman-Codierung ermöglicht eine verlustfreie Datenkompression, indem sie jeder einzelnen Dateneinheit  eine unterschiedlich lange Folge von Bits zuordnet.Daraus folgt, dass eine gute Möglichkeit zur besseren Verwaltung der dem Modell zugeordneten Ressourcen ist:Erstmal das Netzwerk zu beschneiden, dann zu quantisieren und am Ende die Huffman-Codierung durchzuführen. 

\section{Experiment} \label{Experiment}
\subsection{Lernrate}\label{Experiment:Lernrate}
Wie in \ref{Lernrate} gesehen, die Lernrate sagt uns, wie schnell wir ans Ziel kommen möchten.
\begin{itemize}
	\item $ \eta < \eta_{opt} $:So sind wir sichern, ein lokales oder globales Minimum zu erreichen.Aber die Anzahl der benötigten Iterationen bis zum Minimum steigt offensichtlich an und das Verfahren kann in einem unerwünschten lokalen Minimum stecken bleiben .
	\item $ \eta > \eta_{opt} $:Hier wird die Anzahl der Iterationen zwar verringert, aber das Verfahren ist nicht stabil, denn \textcolor{blue}{in der Nähe vom Minimum oder es} wird über das Minimum ständig hinausgegangen und es ist nicht mehr sichern, zum lokalen oder globalen Minimum zu gelangen.
\end{itemize}
In die Praxis gibt es Methoden und Funktionen, um die Lernrate während des Trainings anzupassen. z.B die \textit{KERAS} Funktion \textit{ReduceLROnPlateau}, die die Lernrate reduziert, wenn das \ac{NN} nach einer bestimmten Anzahl von Epochen keine Verbesserung mehr aufweist.



\subsection{Besondere \acsp{CNN}}
\subsubsection{AlexNet}
Wie in \ref{Entwicklung} schon erwähnt, wurde AlexNet von \textit{Alex Krizhevsky} et al \cite{AlexNet} im Jahr 2012 entwickelt. AlexNet hat $ 60 $ Millionen Parametern und etwas $ 650.000 $ Neuronen, besteht aus fünf \acsp{ConvL}, von denen einige von Max-\acsp{PooL} gefolgt sind, und drei \acsp{FCL}(siehe Abbildung \ref{fig:AlexNet}) \cite{AlexNet}.Das Besondere an AlexNet ist aber nicht die Anzahl der Schichten, sondern der Einsatz bestimmter Methoden oder Techniken:
\begin{itemize}
	\item \textbf{ReLU}: Vor AlexNet waren $ tanh $ und $ sigmoid $ die Standard Aktivierungsfunktionen, aber wegen ihrer Sättigung bei hohen oder sehr niedrigen Werten und der Tatsache, das sie in diesen Bereichen eine Steigung nahe bei null haben, verlangsamen sie stark die Gewichtsanpassungen, was nicht der Fall bei $ ReLU $ ist, das eine Steigung gleich null nur bei negativen Werten und bei positiven höheren Werte  eine Steigung nicht nahe bei null hat. Das Training von \ac{CNN} wird durch $ ReLU $  um ein Vielfaches schneller als ein Äquivalent mit $ tanh $ beschleunigt\cite{AlexNet}.
	
	\item \textbf{Überlappendes Pooling}: Die normalen \acsp{PooL} funktioniert wie in \ref{Pooling Layer} ($ pool\_size = stride$), aber die Überlappenden verwenden einfach ein $ stride $ kleiner als das $ pool\_size $.Nach \cite{AlexNet} verbessern die überlappenden \ac{PooL}  die Netzgenauigkeit und macht das Netz gegenüber Overfitting robuster.
	\item \textbf{Dropout und Data Augmentation }: Ein anderer Vorteil von AlexNet ist die Verwendung von Dropout in \acsp{FCL}, das sich heute als die beste oder eine der besten Regulierungsmethoden erweist und der Vermehrung der Daten durch Spiegelung, die die Wahrscheinlichkeit von Overfitting reduziert.
\end{itemize}
\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth ]{AlexNet}
	\caption{ AlexNet Architektur \href{https://neurohive.io/en/popular-networks/alexnet-imagenet-classification-with-deep-convolutional-neural-networks/}{ zum Bild} }
	\label{fig:AlexNet}
\end{figure}


AlexNet kann aufgrund seiner Größe($\sim240MB$) nicht immer auf Systemen mit begrenztem Speicherplatz eingesetzt werden, deshalb ist man seit AlexNet ständig auf der Suche nach neuen Architekturen, die weniger Parameter und Speicherplatz brauchen und  gleichzeitig die Ergebnisse auf der Stand der Technik erreichen. Es ist sicherlich  in diesem Zusammenhang, dass viele neue effiziente Modelle wie $ SqueezeNet $, $ Xception $ und $ MobileNet $ entstanden sind.\\


\subsubsection{SqueezeNet}
$ SqueezeNet $ von \cite[Song Han et al]{SqueezeNet} erreicht die Genauigkeit von AlexNet mit 50x weniger Parametern und  einer Größe kleiner als $ 0.5MB$. Die $ SqueezeNet $ Architektur und einige Variante davon können in Abbildung \ref{fig:SqueezeNet} entnehmen. Zum Erreichen einer solchen Architektur werden drei Hauptstrategien und ein spezieller Block verwendet.Bezüglich dieser Strategien wurde zuerst die meisten $ 3\times3 $ Filter durch $ 1\times1 $ Filter ersetzt, was die Parameteranzahl stark reduziert, denn ein $ 1\times1 $ Filter nimmt $ 9\times $ weniger Parameter als ein $ 3\times3 $ Filter in Anspruch, dann wird die Anzahl der Eingangkanäle auf $ 3\times3 $ Filter verringern, denn die Tiefe eines Filters in einem \ac{ConvL} ist gleich die Tiefe vom \ac{ConvL} Input und ein Input mit einer großen Tiefe wird die Parameteranzahl deutlich zunehmen, obwohl Filter mit kleiner räumlicher Dimension benutzt werden. Die letzte Strategie besteht darin, die Reduzierung der räumlichen Dimension im Netzwerk zu verzögern, so werden Feature-Maps mit größerer Raumauflösung am Ende enthalten. \cite[Song Han et al]{SqueezeNet} sind der Meinung, dass größere Feature-Maps zu einer höheren Klassifizierungsgenauigkeit führen. 

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth ]{squeezenet}
	\caption{ SqueezeNet Architekturen \cite{SqueezeNet} }
	\label{fig:SqueezeNet}
\end{figure}

Um die Ziele der ersten und zweiten Strategien zu erreichen, wird ein neuer Baustein(\textit{fire module})(FM) eingeführt. Das FM besteht aus einem \textit{Squeeze}-(mit $ 1\times1 $ Filtern) und einem \textit{Expand}(mit $ 1\times1 $ und $ 3\times3 $ Filtern)-Block(siehe Abbildung\ref{fig:fire_module}). Der \textit{Squeeze} Block ermöglicht der Reduzierung der Dimensionalität, indem die Anzahl Feature-Maps verringert wird, während die wichtigsten Features erhalten bleiben und die Anwendung von $ ReLU $ nach dem \textit{Squeeze} Block ermöglicht dem Netzwerk, komplexere Features zu lernen.

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth ]{fire_module}
	\caption{ fire\_module \cite{SqueezeNet} }
	\label{fig:fire_module}
\end{figure}

Was der \textit{Expand} Block angeht, funktioniert der Block mit $ 1\times1 $ Filtern genauso wie der \textit{Squeeze} Block und der Block mit $ 3\times3 $ Filtern ermöglicht der Erlangung von Empfangsfelder(\textit{receptive field}), die in der Lage sind, lokale räumliche Informationen zu erfassen, was $ 1\times1 $ Filter nicht schaffen können.

Wie es in Abbildung \ref{fig:SqueezeNet} zu sehen ist, kann eine Verbindung zwischen zwei Layers über eine oder mehrere Schichte überspringen.Solche Verbindungen werden \textit{Residual connections}(RC) genannt und Netze mit RCs gehören zu der Klasse von Residual Netzwerke (mehr dazu siehe \cite{ResNet}).
Wie die Abbildung ?? zeigt, liefert \textit{SqueezeNet} mit Simple RCs  als die anderen Varianten

\subsubsection{Xception: Extreme Inception}
\textit{Xception} ist eine Variante von \textit{InceptionV3}
\textbf{Related work}
\begin{itemize}
	\item Inception Familly
	\item Depthwise separable convolutions
	\item Residual Connection
	\item Die Leistungssteigerungen sind nicht auf eine Kapazitätssteigerung zurückzuführen, sondern auf eine effizientere Nutzung der Modellparameter.
	
\end{itemize}
\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth ]{Xception}
	\caption{ Xception Architektur}
	\label{fig:Xception}
\end{figure}
\subsubsection{MobileNet}
\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth,height=0.8\linewidth]{MobileNet}
	\caption{ MobileNet Architektur }
	\label{fig:MobileNet}
\end{figure}



\subsection{Algorithmen zur Optimierung des Gradientenabstiegsverfahren:	Optimizer}
Die Wahl des Optimierungsalgorithmus für ein \ac{CNN} kann den Unterschied zwischen guten Ergebnissen in Minuten, Stunden und Tagen ausmachen.
\subsubsection{Adaptive Gradient Algorithm (AdaGrad)}
AdaGrad bietet während des Netztrainings nicht nur die Möglichkeit, die Lernrate zu verändern, sondern auch für jeden Parameter eine geeignete Lernrate zu finden. Die AdaGrad-Aktualisierungsregel ergibt sich aus der folgenden Formel:
\begin{equation}\label{adagrad}
\begin{aligned}
\alpha_{t}=&\sum_{i = 1}^{t}{(g_{i-1})^2} &
\theta_{t+1} =& \theta_{t} -\eta_{t} g_t \\ \eta_{t} =& \frac{\eta}{\sqrt{\alpha_{t}}+\epsilon}
\end{aligned}
\end{equation}
\begin{center}
	Voreingestellte Parameter(\textit{KERAS}) :
	\begin{tabular}{r@{= }l c@{= }c r@{= }l}
		$ \alpha_{0} $& 0.0 & $ \eta$& 0.001& $ \epsilon $ & $ 10^{-7} $
	\end{tabular}
\end{center}
Dabei wird am Trainingsanfang eine Lernrate für jeden Parameter definiert und im Trainingsverlauf separat angepasst. 
Dieses Verfahren eignet sich gut für spärliche Daten, denn es gibt häufig auftretende Merkmale sehr niedrige Lernraten und seltene Merkmale hohe Lernraten, wobei die Intuition ist, dass jedes Mal, wenn eine seltene Eigenschaft gesehen wird, sollte der Lernende mehr aufpassen. Somit erleichtert die Anpassung das Auffinden und Identifizieren sehr voraussehbarer, aber vergleichsweise seltener Merkmale.\cite{AdaGrad}.Wie in der Gleichung \eqref{adagrad} festzustellen,nach einer bestimmten Anzahl von Iterationen haben wir keine Verbesserung der Netzleistung, denn je größer $ t $ wird, desto kleiner $ \eta_{t} $ wird und irgendwann wird $ \eta_{t} $ so klein, dass $ \eta_{t}g_{t} $ fast gleich null ist.

\subsubsection{Root Mean Square Propagation(RMSProp)}
RMSProp wie AdaGrad findet für jeden Parameter eine geeignete Lernrate und zur Anpassung der Netzparameter basiert der RMSProp Optimizer auf den Durchschnitt der aktuellen Größen der Gradienten statt auf der Summe der ersten Moment wie in AdaGrad.Da $ E[g^2]_t $ nicht schneller als $ \alpha_{t} $\eqref{adagrad} ansteigt, wird die radikal sinkenden Lernraten von Adagrad deutlich verlangsamt.Die Parameteranpassungen richten sich nach der folgenden Gleichung:
\begin{equation}\label{RMSProp}
\begin{split}
E[g^2]_t =\alpha E[g^2]_{t-1} +(1-\alpha)g^2_{t}\\
\theta_{t+1} = \theta_{t} -\frac{\eta}{\sqrt{E[g^2]_t}+\epsilon} g_t, \quad  \epsilon \approx 0
\end{split}
\end{equation}
Der RMSProp funktioniert besser bei Online- und nicht-stationären Problemen.

\subsubsection{Adaptive Moment Estimation(Adam)}
Der Adam\cite{adam} Optimizer ist auch ein adaptiver Algorithmus,der die ersten und zweiten Momente der Gradienten schätzt, um individuelle adaptive Lernraten für verschiedene Parameter zu berechnen.
Adam weist die Hauptvorteile von AdaGrad, das mit spärlichen Gradienten gut funktioniert, und RMSProp, das einige Probleme von AdaGrad löst und das für nicht-konvexe Optimierung geeignet ist,auf.Wie die Parameteranpassung von Adam Optimizer genau funktioniert, ergibt sich aus der folgenden Gleichung: 
\begin{equation}\label{ADAM}
\begin{aligned}
m_{t}=& \beta_{1}m_{t-1}+(1-\beta_{1})g_{t}, &  \widehat{m}_{t} =& \dfrac{m_{t}}{1-\beta_{1}^t}\\
v_{t}=& \beta_{2}v_{t-1}+(1-\beta_{2})g^2_t,&\widehat{v}_{t} =&\dfrac{v_t}{1-\beta_{2}^t}\\
\theta_{t+1} =& \theta_{t} -\dfrac{\eta}{\sqrt{\widehat{v}_{t}}+\epsilon}\widehat{m}_{t}
\end{aligned}
\end{equation}
\begin{center}
	Voreingestellte Parameter(\textit{KERAS}) :
	\begin{tabular}{r@{: }l r@{: }l}
		$ \beta_{1}$ & 0.9 &$ \beta_{2} $& 0.999\\
		$ \eta$& 0.001& $ \epsilon $ & $ 10^{-7} $
	\end{tabular}
\end{center}

Zu weiteren Vorteile der Nutzung von Adam gehört auch seine Einfachheit zur Implementierung, effizienter Nutzung der Speicherplatz und seine Invarianz zur diagonalen Neuskalierung der Gradienten.
\\ \textcolor{purple}{Kleines Experiment}


\subsection{Problem beim Training von  Convolutional   neuronale Netzwerke}
\subsubsection{Overfitting }\label{Overfitting}
%\textcolor{red}{\begin{itemize}
%		\item Erinnern Sie sich an das Kind aus Ihrer Mittelschulklasse, das bei den Tests sehr gut abgeschnitten hat, aber es schlecht tat, wenn die Fragen zum Test ursprüngliches Denken erforderten und nicht in der Klasse behandelt wurden? Warum tat er dies schlecht, wenn er mit einem Problem konfrontiert wurde, das er noch nie zuvor gesehen hatte? Weil er sich die Antworten auf die in der Klasse behandelten Fragen gemerkt hatte, ohne die zugrunde liegenden Konzepte zu verstehen.
%		\item Ebenso ist die Größe des Neuronalen Netzwerks seine Fähigkeit zu lernen, aber wenn Sie nicht vorsichtig sind, wird es versuchen, die Beispiele in den Trainingsdaten zu speichern, ohne das Konzept zu verstehen. Infolgedessen wird das Neuronale Netzwerk außergewöhnlich gut mit den Trainingsdaten arbeiten, aber sie lernen nicht das eigentliche Konzept. Es wird bei neuen und unsichtbaren Testdaten nicht gut funktionieren. Dies wird als Überfitting bezeichnet.
%	\end{itemize}
%}
Wenn ein von der Maschine gelerntes Modell zu gut auf die Trainingsdaten abgestimmt ist und sehr schlechte Vorhersagen über Daten macht, die es bisher nicht gesehen hat, wird gesagt, dass das Modell an Überanpassung(Overfitting) leidet, anders gesagt, das Modell war nicht in der Lage, die relevanten Merkmale aus den Trainingsdaten zu verallgemeinern, sondern die ganzen Trainingsdaten auswendig zu lernen.Die irrelevanten Informationen aus den Trainingsdaten können z.B die Position des Tellers in einem Bild sein, wenn man Essen klassifizieren sollte. Im folgenden werden einige Mittels vorgestellt, um mit Overfitting umzugehen.\\
\begin{center}
	\textbf{Strategie gegen Overfitting}
\end{center}
\subparagraph{{Data Augmentation}}\label{Data Augmentation}
Ein großer Datensatz ist entscheidend für die Leistung tiefer neuronaler Netze.Dass ein Datensatz groß oder ausreichend für das Training eines \ac{NN}s ist, hängt nur von der Größe des \ac{NN}s ab und da die \acsp{NN}, die die besten Leistungen aufweisen, Millionen von Parametern haben, ist fast unmöglich für jedes  Problem von Maschine Lernen ausreichende Daten zu finden.Anstatt immer neue Daten zur Verbesserung der Netzleistung zu sammeln, können wir die Leistung des Modells verbessern, indem wir neue Daten von den bereits vorhandenen Daten aus erzeugen.\\
Die populären Techniken oder Transformationen zur Vermehrung des Datensatzes sind die horizontalen oder vertikalen Spiegelungen, Drehungen, Skalierungen, Zuschneiden, Parallelverschiebungen und die Gauß'sches Rauschen.
Für diese Arbeit habe ich zwei Ansätze im Gebrauch gehabt, um den Datensatz zu erhöhen:
Der erste Ansatz besteht darin vor dem Training neue Daten zu erzeugen. Dabei werden die oben erwähnten Techniken vor dem Training angewendet, um zum Trainingszeitpunkt und zur Testzeit einen großen Datensatz zu haben und die originalen Daten werden zur Validierung verwendet.Der zweite Ansatz besteht darin, zum Trainingszeitpunkt und zur Testzeit die neuen Daten zu erzeugen. Hier haben wir keinen Datensatz größer als den originalen, aber die Daten, die ins Netzwerk eingespeist werden, ändern sich ständig.Angenommen wir die Möglichkeit haben, alle diese Transformationen durchzuführen, dann kann es vorkommen, dass eine Photo während der ersten Epoche horizontal gespiegelt wird und während der zweiten um  zwanzig Grad gedreht wird, umso weiter.Zur Implementierung des zweiten Ansatzes bietet \textit{KERAS} Framework die Funktion \textit{ImageDataGeneerator}. Das interessanteste an \textit{ImageDataGeneerator} ist, dass es mehrere Transformationen gleichzeitig anwenden(siehe Abbildung \ref{fig:ImageDataAugmentation}).

\begin{figure}[h]
	\centering
	\includegraphics{ImageDataAugmaentation.png}
	\caption{Anwendung von \textit{ImageDataAugmentation} }
	\label{fig:ImageDataAugmentation}
\end{figure}

Je mehr Daten verfügbar sind, desto effektiver können die \acsp{CNN} sein. Es ist also mehr als wichtig über eine große Datenmenge zu verfügen. Leider können die gesammelten Datensätze nicht alle mögliche Szenarios des reellen Lebens abdecken,deshalb ist es auch bedeutend, \ac{CNN}  mit zusätzlichen synthetisch modifizierten Daten zu trainieren. Die \acsp{CNN} funktionieren glücklicherweise besser oder immer gut, solange nützliche Daten durch das Modell aus dem ursprünglichen Datensatz extrahiert werden können, selbst wenn die erzeugten Daten von geringerer Qualität sind.\\


\subparagraph{Dropout}  \label{Dropout}
Künstliche Neurone sind von biologischen Neuronen inspiriert, aber die Beiden unterscheidet sich sehr voneinander und einer der wichtigen Unterschiede ist, dass biologische Neuronen unvollkommene Maschinen sind, die sehr oft nicht richtig funktioniert und das ist a priori nie den Fall bei  künstlichen Neuronen. Wir könnten also glauben, dass \ac{KNN} die biologische übertreffen könnten.Es sei denn, dass diese Funktionsstörung von biologischen Neuronen nicht eine Schwäche ist, sondern eher eine Stärke ist.Eine der verblüffenden Entdeckungen in \ac{KI} Bereich ist, dass es wünschenswert ist, künstliche Neuronen von Zeit zu Zeit zu Fehlfunktionen zu bringen\cite{1}. \textcolor{blue}{Jetzt können wir uns fragen, wie Dysfunktion von Neuronen die Performances \acsp{CNN} verbessern kann}.Die zufällige Hinzufügen von Dysfunktionen in einer Schicht der \ac{CNN} wird \textit{Dropout} benannt und wurde von \cite[Geoffrey E. et al]{2} eingeführt.
\subparagraph{Funktionsweise von Dropout}.\\
Genauer gesagt,Dropout bezeichnet die zeitliche zufällige Ausschaltung von Neuronen(versteckt und sichtbar)  in einem  \ac{NN} \cite{3}. Wie die Abbildung \ref{fig:Dropout} zeigt, wenn ein Neuron zufällig aus dem \ac{NN} entfernt wird, werden auch all seine ein- und ausgehenden Verbindungen entfernt.
In einer Dropout-Schicht wird ein Neuron $ \textit{N} $ unabhängig von anderen Neuronen mit einer Wahrscheinlichkeit $ {p} $ zurückgehalten, d.h $ \textit{N} $ wird mit einer Wahrscheinlichkeit von $ {p} $ nicht am Ergebnis der Schicht teilnehmen. Während der Testphase  werden alle Verbindungen zurückgesetzt, die während des Trainings gelöscht wurden und die ausgehenden Verbindungen gelöschter Neurone mit $ p $   multipliziert.

\begin{figure}[h]
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[scale=2, width=.8\linewidth, height=\linewidth]{dropout1.png}
		\caption{Standard neuronale Netze}
		\label{fig:dropout1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.8\linewidth, height=\linewidth, scale=2]{dropout2.png}
		\caption{Netze nach Dropout}
		\label{fig:dropout2}
	\end{subfigure}
	\caption{Neuronales Netz mit Dropout ausgestattet \cite{3}.}
	\label{fig:Dropout}
\end{figure}

\subparagraph{Verhinderung der Koadaptationen zwischen Neuronen}.\\
Während des Trainings können mehrere Neurone zur Minimierung der Fehlerfunktion so gut zusammenarbeiten, dass die Erkennung bestimmter Merkmale ohne diese Zusammenarbeit nicht mehr möglich ist, aber solche komplexe Koadaptationen  können zu einer Überanpassung führen, denn diese komplexe Koadaptationen existieren nicht immer in Testdaten. Da die am Training teilnehmenden Neuronen nach dem Zufallsprinzip nach jeder Epoche ausgewählt werden, haben wir für jedes Training ein neues Modell, was die Neuronen zur Zusammenarbeit zwingt, ohne jedoch voneinander abhängig zu sein, anders gesagt, wird jedes Neuron unabhängig von anderen Neuronen die Muster korrekt lernen können.  

\subparagraph{Automatische Erhöhung von Training Daten und Regelung }.\\
Noch dazu führt die Ausschaltung von Neuronen, wie es in Abbildung \ref{fig:DropoutDataAugmentation} angezeigt ist, zu einer automatische Erzeugung neuer Trainingsdaten. Die verwendeten Daten in ausgedünnten Modellen sind also nur eine Abstraktion von echten Daten bzw. Rauschdaten und da wir für ein Netz mit $ n $ versteckten Einheiten, von denen jede fallen gelassen werden kann, $ 2^n $ mögliche Modelle haben, haben wir $ 2^n $ mögliche Abstraktion von unseren Daten und das sollte einer der Gründe sein, warum Dropout effektiver als andere rechnerisch kostengünstige Regler ist \cite{3} und warum die Trainingszeit von \acsp{NN} mit Dropout mindestens verdoppelt wird. 

\begin{figure}[h]
	\centering
	\includegraphics{model}
	\caption{Erhöhung des Trainingsdaten durch Dropout}
	\label{fig:DropoutDataAugmentation}
\end{figure}

Da heutige \acsp{CNN} Million von Neurons haben, wäre es unmöglich alle mögliche ausgedünnte Netzwerke zu trainieren, deshalb ist das Modell, das am Ende des Trainings erhalten wird, nur eine durchschnittliche Approximation aller mögliche Modelle, was schon gut, denn es gibt schlechte und gute Modelle.
%\textcolor{red}{\\\textbf{NICHT LESEN}\\ Wenn ich einem 6-jährigen Aussteiger erklären muss, dann so: Stellen Sie sich ein Szenario vor, in einem Klassenzimmer, ein Lehrer stellt einige Fragen, aber immer die gleichen zwei Kinder beantworten sofort. Nun bittet der Lehrer sie, für einige Zeit still zu bleiben und andere Schüler teilnehmen zu lassen. Auf diese Weise können andere Schüler besser lernen. Vielleicht antworten sie falsch, aber der Lehrer kann sie korrigieren (Gewichtsaktualisierungen). Auf diese Weise lernt die gesamte Klasse (Layer) besser über ein Thema.}

\subparagraph{Batch-Normalisierung}\label{Batch-Normalisierung}
Das Training tiefer neuronaler Netze ist sehr kompliziert und ein Grund dafür ist zum Beispiel die Tatsache, dass die Parameter einer Schicht während des Trainings tiefer neuronaler Netze immer unter der Annahme, dass sich die Parameter anderer Schichten nicht ändern, aktualisiert werden und da alle Schichten während des Updates geändert werden, verfolgt das Optimierungsverfahren ein Minimum, das sich ständig bewegt. Ein anderer Grund dafür ist die ständigen Veränderungen im Laufe des Trainings in die Verteilung des Netzinputs, diese Veränderung wird von \cite{bactchnormalisation} als interne kovariate Verschiebung(\textit{Internal Covariate Shift}) genannt.Zur Lösung dieser Probleme schlagen \textit{LeCunn et al}\cite{LeCun} vor dem Training das Netzinput zu normalisieren. Aber dieser Ansatz bringt nicht so viel, wenn das \ac{NN} wirklich tief ist, denn nur der Netzinput profitiert von der Normalisierung und die kleinen Veränderungen in versteckte Schichten werden sich immer mehr verstärken, je tiefer man das Netz durchläuft. Mit der Ausbreitung tiefer \acsp{NN} dehnt Batch-Normalisierung(BN)\cite{bactchnormalisation} diese Idee der Datennormalisierung auf versteckte Schichten tiefer \acsp{NN} aus. Bei der BN werden die Eingaben in einem Netzwerk standardisiert, die entweder auf die Aktivierungen einer vorherigen Schicht oder auf direkte Eingaben angewendet wird, so standardisiert, dass der Mittelwert in der Nähe von null liegt und die Standardabweichung in der Nähe von eins liegt. Die BN wird über Mini-Batches und nicht über den gesamten Trainingssatz durchgeführt, daher enthalten wir nur Näherungen an tatsächliche Werte der Standardabweichung und des Mittelwerts über das Trainingssatzes, aber wir gewinnen an Geschwindigkeit und an Speicherplatzverbrauch.Die Gleichung \eqref{BNA} gibt die formale Beschreibung des BN Algorithmus an.
\begin{center}
	Batch-Normalisierungstransformation, angewendet auf Aktivierung x über einen Mini-Batch
\end{center}
\begin{subequations}
	\begin{align*}
	\textbf{Input:} & \text{  Werte von x über einer Mini-Batch: } B=\{x_{1...m}\}\\
	& \text{Lernbare Parameter  } \beta, \gamma \\
	\textbf{Output:} & \{ y_i = BN_{\beta, \gamma}(x_i)\}
	\end{align*}
	\begin{align}
	\text{Mini-Batch Mittelwert  : } &\mu_\beta=\frac{1}{m}\sum_{i = 1}^{m}x_i \\
	\text{ Mini-Batch Standardabweichung :} &\sigma_\beta^2=\frac{1}{m}\sum_{i = 1}^{m}(x_i- \mu_\beta)^2 \\
	\text{Normalisierung:} & \widehat{x_i} = \frac{x_i - \mu_\beta}{\sqrt{\sigma_\beta^2 + \epsilon}} \\
	\text{Skalierung und Verschiebung :} & {y_i} = \gamma\widehat{x_i} + \beta \equiv BN_{\gamma, \beta}
	\end{align}
	\label{BNA}
\end{subequations}
Wenn $\gamma = \sqrt{\sigma_\beta^2 + \epsilon}$ und $\beta = \mu_\beta $, bekommen wir die gleiche Verteilung wie vor der Batch-Normalisierung, d.h die Eingabe war also schon normalisiert. Interessanterweise kann das Netz während des Trainings eine bessere Verteilung als die erwünschte finden, denn $\gamma$ und $\beta$ sind lernbare Parameter.

Durch die BN kann zum einen eine hohe Lernrate verwendet,was in tiefer \acsp{NN} ohne BN dazu führen kann, dass die Gradienten explodieren oder verschwinden und in schlechten lokalen Minima stecken bleiben.Die Verwendung einer höhere Lernrate ermöglicht einer schnellere Konvergenz.
Zum anderen wird die interne kovariate Verschiebung geringer, was das Training beschleunigt, in einigen Fällen durch Halbierung der Epochen oder besser. Noch dazu wird das Netz durch die BN in gewissem Maße reguliert, daher wird die Verwendung von Dropout bzw. Regulierungstechnik reduziert oder sogar überflüssig und somit eine Verbesserung der Verallgemeinerungsgenauigkeit.
\subsubsection{Dataset}
\section{Abkürzungsverzeichnis}
\begin{acronym}[THIBAUT]
	\acro{KNN}{Künstliches neuronales Netz}
	\acro{CNN}{Convolutional Neural Network}
	\acro{KI}{Künstliche Intelligenz}
	\acro{NN}{neuronales Netz}
	\acro{ConvL}{Convolutional Layer}
	\acro{FCL}{Fully Connected Layer}
	\acro{PooL}{Pooling Layer}
	\acro{ILSVRC }{ Large Scale Visual Recognition Challenge}
	\acro{DNN}{Tiefe neuronale Netze}
\end{acronym}

\bibliographystyle{acm}

\begin{thebibliography}{lem00}
 \bibitem{1}
	P. Kerlirzin, and F. Vallet: \href{ https://www.mitpressjournals.org/doi/abs/10.1162/neco.1993.5.3.473?journalCode=neco} {Robustness in Multilayer Perceptrons}
 \bibitem{2}
 	Geoffrey E. Hinton and Nitish Srivastava and Alex Krizhevsky and Ilya Sutskever and Ruslan R. Salakhutdinov: \href{https://arxiv.org/abs/1207.0580}{Improving neural networks by preventing co-adaptation of feature detectors}
 \bibitem{3}
 	Srivastava, Hinton, Krizhevsky, Sutskever and Salakhutdinov: \href{http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf}{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}
\bibitem{4}
Ian Goodfellow, Yoshua Bengio, Aaron Courville:
\href{https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=as_li_ss_tl?ieTF8&qid=1548018253&sr=8-3&keywords=deep+learning&linkCode=sl1&tag=inspiredalgor-20&linkId=49b3b1cce7e04bb3c9b99f2d878bf805&language=en_US}{Adaptive Computation and Machine Learning series} Page 342
 
 \bibitem{5}
	 Song Han, Huizi Mao, William J. Dally \href{https://arxiv.org/abs/1510.00149}{Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding}
 \bibitem{Automated Pruning}
      Franco Manessi, Alessandro Rozza, Simone Bianco, Paolo Napoletano, Raimondo Schettini \href{https://arxiv.org/abs/1712.01721}{Automated Pruning for Deep Neural Network Compression}
 \bibitem{7}
 	 Pavel Golik , Patrick Doetsch, Hermann Ney
 	\href{http://books.jackon.me/Cross-Entropy-vs-Squared-Error-Training-a-Theoretical-and-Experimental-Comparison.pdf}{Cross-Entropy vs. Squared Error Training:a Theoretical and Experimental Comparison}
 	
 \bibitem{8}
 	\href{http://www.neuronalesnetz.de/aktivitaet.html}{Neuronale Netze:Eine Einführung}
 	
 \bibitem{bactchnormalisation}
	Sergey Ioffe, Christian Szegedy
 	\href{https://arxiv.org/pdf/1502.03167.pdf}{Batch Normalization: Accelerating Deep Network Training b
 		y
 		Reducing Internal Covariate Shift}

	\bibitem{LearningRate}Wikipedia:
		\href{https://en.wikipedia.org/wiki/Learning_rate}{Learning Rate}
	\bibitem{AdaGrad}
		John Duchi,Elad Hazan, Yoram Singer:
		\href{http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf}{Adaptive Subgradient Methods for
			Online Learning and Stochastic Optimization}
	\bibitem{adam}
		Diederik P. Kingma, Jimmy Ba:
		\href{https://arxiv.org/abs/1412.6980}{Adam: A Method for Stochastic Optimization}
		
	\bibitem{quantization1}
		\href{https://nervanasystems.github.io/distiller/quantization.html}{Compressing Models:Quantization}
	\bibitem{quantizationYoni}
		Yoni Choukroun, Eli Kravchik, Fan Yang, Pavel Kisilev:
			\href{https://arxiv.org/abs/1902.06822}{Low-bit Quantization of Neural Networks for Efficient Inference}
	\bibitem{kneuron}
	wikipedia:\href{https://en.wikipedia.org/wiki/Artificial_neuron}{ Artificial neuron}
	\bibitem{AlexNet}Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton
		\href{https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}{ImageNet Classification with Deep Convolutional Neural Networks}
  
  \bibitem{SqueezeNet}
  	Forrest N. Iandola, Song Han, Matthew W. Moskewicz, Khalid Ashraf, William J. Dally, Kurt Keutzer:
  	\href{https://arxiv.org/abs/1602.07360}{SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size}
  	\bibitem{ResNet}
  		Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun:
  		\href{https://arxiv.org/pdf/1512.03385.pdf}{Deep Residual Learning for Image Recognition}
\end{thebibliography}

 
      
  % ggf. hier Tabelle mit Symbolen 
  % (kann auch auf das Inhaltsverzeichnis folgen)

\newpage
  
 \thispagestyle{empty}


\vspace*{8cm}


\section*{Erklärung}

Ich  versichere  wahrheitsgemäß,  die  Arbeit selbstständig verfasst,  alle  benutzten  Hilfsmittel  vollständig  und  genau  angegeben  und  alles kenntlich  gemacht  zu  haben,  was  aus  Arbeiten  anderer  unverändert  oder  mit  Abänderungen entnommen  wurde,  sowie die Satzung  der  Universität Augsburg  zur  Sicherung guter wissenschaftlicher Praxis in der jeweils gültigen Fassung beachtet zu haben.
\\[2ex] 

\noindent
Ort, den Datum\\[5ex]

% Unterschrift (handgeschrieben)



\end{document}

